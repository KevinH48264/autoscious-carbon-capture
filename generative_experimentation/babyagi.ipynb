{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load default environment variables (.env)\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from collections import deque\n",
    "from typing import Dict, List\n",
    "import importlib\n",
    "import openai\n",
    "import chromadb\n",
    "import tiktoken as tiktoken\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from chromadb.api.types import Documents, EmbeddingFunction, Embeddings\n",
    "import re\n",
    "import json\n",
    "from search import search_web_for_facts\n",
    "\n",
    "# default opt out of chromadb telemetry.\n",
    "from chromadb.config import Settings\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_full_text = False\n",
    "if debug_full_text:\n",
    "    class FlushingFile:\n",
    "        def __init__(self, file):\n",
    "            self.file = file\n",
    "        def write(self, s):\n",
    "            self.file.write(s)\n",
    "            self.file.flush()\n",
    "        def close(self):\n",
    "            self.file.close()\n",
    "    original_stdout = sys.stdout\n",
    "    f = open('output.txt', 'a')\n",
    "    sys.stdout = FlushingFile(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CO2 capture rate', 'Feasibility', 'Cost per metric ton of CO2 captured', 'Storage capacity', 'Permanence', 'Energy consumption', 'Environmental impact', 'Easily measurable']\n"
     ]
    }
   ],
   "source": [
    "file_name = f'metrics.json'\n",
    "\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    metrics = json.loads(f.read())\n",
    "print(list(metrics.keys()))\n",
    "metrics_list = list(metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = \"Suggest novel and actionable research designs and solutions that could potentially carbon capture 1 Gt of CO2 per year ASAP. Your constraints are 1) you can only leverage knowledge on the web to reason your way to potentially impactful hypotheses, 2) this is independent research work with only 1 human collaborator responsible for conducting physical experiments, and 3) you cannot seek outside funding and must work to minimize the budget but maximize impact.\"\n",
    "context = '''Metrics:\n",
    "{metrics_list}\n",
    "'''\n",
    "initial_task = \"Develop a research strategy to achieve the objective. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "\n",
    "# Engine configuration\n",
    "\n",
    "# Goal configuration\n",
    "OBJECTIVE = objective or os.getenv(\"OBJECTIVE\", \"\")\n",
    "INITIAL_TASK = initial_task or os.getenv(\"INITIAL_TASK\", os.getenv(\"FIRST_TASK\", \"\"))\n",
    "\n",
    "# Model: GPT, LLAMA, HUMAN, etc.\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", os.getenv(\"OPENAI_API_MODEL\", \"gpt-3.5-turbo\")).lower()\n",
    "\n",
    "# API Keys\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "if not (LLM_MODEL.startswith(\"llama\") or LLM_MODEL.startswith(\"human\")):\n",
    "    assert OPENAI_API_KEY, \"\\033[91m\\033[1m\" + \"OPENAI_API_KEY environment variable is missing from .env\" + \"\\033[0m\\033[0m\"\n",
    "\n",
    "# Table config\n",
    "RESULTS_STORE_NAME = os.getenv(\"RESULTS_STORE_NAME\", os.getenv(\"TABLE_NAME\", \"\"))\n",
    "assert RESULTS_STORE_NAME, \"\\033[91m\\033[1m\" + \"RESULTS_STORE_NAME environment variable is missing from .env\" + \"\\033[0m\\033[0m\"\n",
    "\n",
    "# Run configuration\n",
    "INSTANCE_NAME = os.getenv(\"INSTANCE_NAME\", os.getenv(\"BABY_NAME\", \"BabyAGI\"))\n",
    "COOPERATIVE_MODE = \"none\"\n",
    "JOIN_EXISTING_OBJECTIVE = False\n",
    "\n",
    "# Model configuration\n",
    "OPENAI_TEMPERATURE = float(os.getenv(\"OPENAI_TEMPERATURE\", 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extension support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions support begin\n",
    "\n",
    "def can_import(module_name):\n",
    "    try:\n",
    "        importlib.import_module(module_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "\n",
    "DOTENV_EXTENSIONS = os.getenv(\"DOTENV_EXTENSIONS\", \"\").split(\" \")\n",
    "\n",
    "# Command line arguments extension\n",
    "# Can override any of the above environment variables\n",
    "ENABLE_COMMAND_LINE_ARGS = (\n",
    "        os.getenv(\"ENABLE_COMMAND_LINE_ARGS\", \"false\").lower() == \"true\"\n",
    ")\n",
    "if ENABLE_COMMAND_LINE_ARGS:\n",
    "    if can_import(\"extensions.argparseext\"):\n",
    "        from extensions.argparseext import parse_arguments\n",
    "\n",
    "        OBJECTIVE, INITIAL_TASK, LLM_MODEL, DOTENV_EXTENSIONS, INSTANCE_NAME, COOPERATIVE_MODE, JOIN_EXISTING_OBJECTIVE = parse_arguments()\n",
    "\n",
    "# Human mode extension\n",
    "# Gives human input to babyagi\n",
    "if LLM_MODEL.startswith(\"human\"):\n",
    "    if can_import(\"extensions.human_mode\"):\n",
    "        from extensions.human_mode import user_input_await\n",
    "\n",
    "# Load additional environment variables for enabled extensions\n",
    "# TODO: This might override the following command line arguments as well:\n",
    "#    OBJECTIVE, INITIAL_TASK, LLM_MODEL, INSTANCE_NAME, COOPERATIVE_MODE, JOIN_EXISTING_OBJECTIVE\n",
    "if DOTENV_EXTENSIONS:\n",
    "    if can_import(\"extensions.dotenvext\"):\n",
    "        from extensions.dotenvext import load_dotenv_extensions\n",
    "\n",
    "        load_dotenv_extensions(DOTENV_EXTENSIONS)\n",
    "\n",
    "# TODO: There's still work to be done here to enable people to get\n",
    "# defaults from dotenv extensions, but also provide command line\n",
    "# arguments to override them\n",
    "\n",
    "# Extensions support end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m\n",
      "*****CONFIGURATION*****\n",
      "\u001b[0m\u001b[0m\n",
      "Name  : BabyAGI\n",
      "Mode  : alone\n",
      "LLM   : gpt-3.5-turbo\n",
      "\n",
      "Using results storage: \u001b[93m\u001b[1mChroma (Default)\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[95m\\033[1m\" + \"\\n*****CONFIGURATION*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "print(f\"Name  : {INSTANCE_NAME}\")\n",
    "print(f\"Mode  : {'alone' if COOPERATIVE_MODE in ['n', 'none'] else 'local' if COOPERATIVE_MODE in ['l', 'local'] else 'distributed' if COOPERATIVE_MODE in ['d', 'distributed'] else 'undefined'}\")\n",
    "print(f\"LLM   : {LLM_MODEL}\")\n",
    "\n",
    "\n",
    "# Check if we know what we are doing\n",
    "assert OBJECTIVE, \"\\033[91m\\033[1m\" + \"OBJECTIVE environment variable is missing from .env\" + \"\\033[0m\\033[0m\"\n",
    "assert INITIAL_TASK, \"\\033[91m\\033[1m\" + \"INITIAL_TASK environment variable is missing from .env\" + \"\\033[0m\\033[0m\"\n",
    "\n",
    "LLAMA_MODEL_PATH = os.getenv(\"LLAMA_MODEL_PATH\", \"models/llama-13B/ggml-model.bin\")\n",
    "if LLM_MODEL.startswith(\"llama\"):\n",
    "    if can_import(\"llama_cpp\"):\n",
    "        from llama_cpp import Llama\n",
    "\n",
    "        print(f\"LLAMA : {LLAMA_MODEL_PATH}\" + \"\\n\")\n",
    "        assert os.path.exists(LLAMA_MODEL_PATH), \"\\033[91m\\033[1m\" + f\"Model can't be found.\" + \"\\033[0m\\033[0m\"\n",
    "\n",
    "        CTX_MAX = 1024\n",
    "        LLAMA_THREADS_NUM = int(os.getenv(\"LLAMA_THREADS_NUM\", 8))\n",
    "\n",
    "        print('Initialize model for evaluation')\n",
    "        llm = Llama(\n",
    "            model_path=LLAMA_MODEL_PATH,\n",
    "            n_ctx=CTX_MAX,\n",
    "            n_threads=LLAMA_THREADS_NUM,\n",
    "            n_batch=512,\n",
    "            use_mlock=False,\n",
    "        )\n",
    "\n",
    "        print('\\nInitialize model for embedding')\n",
    "        llm_embed = Llama(\n",
    "            model_path=LLAMA_MODEL_PATH,\n",
    "            n_ctx=CTX_MAX,\n",
    "            n_threads=LLAMA_THREADS_NUM,\n",
    "            n_batch=512,\n",
    "            embedding=True,\n",
    "            use_mlock=False,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"\\033[91m\\033[1m\"\n",
    "            + \"\\n*****USING LLAMA.CPP. POTENTIALLY SLOW.*****\"\n",
    "            + \"\\033[0m\\033[0m\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"\\033[91m\\033[1m\"\n",
    "            + \"\\nLlama LLM requires package llama-cpp. Falling back to GPT-3.5-turbo.\"\n",
    "            + \"\\033[0m\\033[0m\"\n",
    "        )\n",
    "        LLM_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "if LLM_MODEL.startswith(\"gpt-4\"):\n",
    "    print(\n",
    "        \"\\033[91m\\033[1m\"\n",
    "        + \"\\n*****USING GPT-4. POTENTIALLY EXPENSIVE. MONITOR YOUR COSTS*****\"\n",
    "        + \"\\033[0m\\033[0m\"\n",
    "    )\n",
    "\n",
    "if LLM_MODEL.startswith(\"human\"):\n",
    "    print(\n",
    "        \"\\033[91m\\033[1m\"\n",
    "        + \"\\n*****USING HUMAN INPUT*****\"\n",
    "        + \"\\033[0m\\033[0m\"\n",
    "    )\n",
    "\n",
    "# Configure OpenAI\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "# Llama embedding function\n",
    "class LlamaEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "\n",
    "    def __call__(self, texts: Documents) -> Embeddings:\n",
    "        embeddings = []\n",
    "        for t in texts:\n",
    "            e = llm_embed.embed(t)\n",
    "            embeddings.append(e)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# Results storage using local ChromaDB\n",
    "class DefaultResultsStorage:\n",
    "    def __init__(self):\n",
    "        logging.getLogger('chromadb').setLevel(logging.ERROR)\n",
    "        # Create Chroma collection\n",
    "        chroma_persist_dir = \"chroma\"\n",
    "        chroma_client = chromadb.Client(\n",
    "            settings=chromadb.config.Settings(\n",
    "                chroma_db_impl=\"duckdb+parquet\",\n",
    "                persist_directory=chroma_persist_dir,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        metric = \"cosine\"\n",
    "        if LLM_MODEL.startswith(\"llama\"):\n",
    "            embedding_function = LlamaEmbeddingFunction()\n",
    "        else:\n",
    "            embedding_function = OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY)\n",
    "        self.collection = chroma_client.get_or_create_collection(\n",
    "            name=RESULTS_STORE_NAME,\n",
    "            metadata={\"hnsw:space\": metric},\n",
    "            embedding_function=embedding_function,\n",
    "        )\n",
    "\n",
    "    def add(self, task: Dict, result: str, result_id: str):\n",
    "\n",
    "        # Break the function if LLM_MODEL starts with \"human\" (case-insensitive)\n",
    "        if LLM_MODEL.startswith(\"human\"):\n",
    "            return\n",
    "        # Continue with the rest of the function\n",
    "\n",
    "        embeddings = llm_embed.embed(result) if LLM_MODEL.startswith(\"llama\") else None\n",
    "        if (\n",
    "                len(self.collection.get(ids=[result_id], include=[])[\"ids\"]) > 0\n",
    "        ):  # Check if the result already exists\n",
    "            self.collection.update(\n",
    "                ids=result_id,\n",
    "                embeddings=embeddings,\n",
    "                documents=result,\n",
    "                metadatas={\"task\": task[\"task_name\"], \"result\": result},\n",
    "            )\n",
    "        else:\n",
    "            self.collection.add(\n",
    "                ids=result_id,\n",
    "                embeddings=embeddings,\n",
    "                documents=result,\n",
    "                metadatas={\"task\": task[\"task_name\"], \"result\": result},\n",
    "            )\n",
    "\n",
    "    def query(self, query: str, top_results_num: int) -> List[dict]:\n",
    "        count: int = self.collection.count()\n",
    "        if count == 0:\n",
    "            return []\n",
    "        results = self.collection.query(\n",
    "            query_texts=query,\n",
    "            n_results=min(top_results_num, count),\n",
    "            include=[\"metadatas\"]\n",
    "        )\n",
    "        return [item[\"task\"] for item in results[\"metadatas\"][0]]\n",
    "\n",
    "\n",
    "# Initialize results storage\n",
    "def try_weaviate():\n",
    "    WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\", \"\")\n",
    "    WEAVIATE_USE_EMBEDDED = os.getenv(\"WEAVIATE_USE_EMBEDDED\", \"False\").lower() == \"true\"\n",
    "    if (WEAVIATE_URL or WEAVIATE_USE_EMBEDDED) and can_import(\"extensions.weaviate_storage\"):\n",
    "        WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\", \"\")\n",
    "        from extensions.weaviate_storage import WeaviateResultsStorage\n",
    "        print(\"\\nUsing results storage: \" + \"\\033[93m\\033[1m\" + \"Weaviate\" + \"\\033[0m\\033[0m\")\n",
    "        return WeaviateResultsStorage(OPENAI_API_KEY, WEAVIATE_URL, WEAVIATE_API_KEY, WEAVIATE_USE_EMBEDDED, LLM_MODEL, LLAMA_MODEL_PATH, RESULTS_STORE_NAME, OBJECTIVE)\n",
    "    return None\n",
    "\n",
    "def try_pinecone():\n",
    "    PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\", \"\")\n",
    "    if PINECONE_API_KEY and can_import(\"extensions.pinecone_storage\"):\n",
    "        PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\", \"\")\n",
    "        assert (\n",
    "            PINECONE_ENVIRONMENT\n",
    "        ), \"\\033[91m\\033[1m\" + \"PINECONE_ENVIRONMENT environment variable is missing from .env\" + \"\\033[0m\\033[0m\"\n",
    "        from extensions.pinecone_storage import PineconeResultsStorage\n",
    "        print(\"\\nUsing results storage: \" + \"\\033[93m\\033[1m\" + \"Pinecone\" + \"\\033[0m\\033[0m\")\n",
    "        return PineconeResultsStorage(OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_ENVIRONMENT, LLM_MODEL, LLAMA_MODEL_PATH, RESULTS_STORE_NAME, OBJECTIVE)\n",
    "    return None\n",
    "\n",
    "def use_chroma():\n",
    "    print(\"\\nUsing results storage: \" + \"\\033[93m\\033[1m\" + \"Chroma (Default)\" + \"\\033[0m\\033[0m\")\n",
    "    return DefaultResultsStorage()\n",
    "\n",
    "results_storage = try_weaviate() or try_pinecone() or use_chroma()\n",
    "\n",
    "# Task storage supporting only a single instance of BabyAGI\n",
    "class SingleTaskListStorage:\n",
    "    def __init__(self):\n",
    "        self.tasks = deque([])\n",
    "        self.task_id_counter = 0\n",
    "\n",
    "    def append(self, task: Dict):\n",
    "        self.tasks.append(task)\n",
    "\n",
    "    def replace(self, tasks: List[Dict]):\n",
    "        self.tasks = deque(tasks)\n",
    "\n",
    "    def popleft(self):\n",
    "        return self.tasks.popleft()\n",
    "\n",
    "    def is_empty(self):\n",
    "        return False if self.tasks else True\n",
    "\n",
    "    def next_task_id(self):\n",
    "        self.task_id_counter += 1\n",
    "        return self.task_id_counter\n",
    "\n",
    "    def get_task_names(self):\n",
    "        return [t[\"task_name\"] for t in self.tasks]\n",
    "\n",
    "\n",
    "# Initialize tasks storage\n",
    "tasks_storage = SingleTaskListStorage()\n",
    "if COOPERATIVE_MODE in ['l', 'local']:\n",
    "    if can_import(\"extensions.ray_tasks\"):\n",
    "        import sys\n",
    "        from pathlib import Path\n",
    "\n",
    "        sys.path.append(str(Path(__file__).resolve().parent))\n",
    "        from extensions.ray_tasks import CooperativeTaskListStorage\n",
    "\n",
    "        tasks_storage = CooperativeTaskListStorage(OBJECTIVE)\n",
    "        print(\"\\nReplacing tasks storage: \" + \"\\033[93m\\033[1m\" + \"Ray\" + \"\\033[0m\\033[0m\")\n",
    "elif COOPERATIVE_MODE in ['d', 'distributed']:\n",
    "    pass\n",
    "\n",
    "\n",
    "def limit_tokens_from_string(string: str, model: str, limit: int) -> str:\n",
    "    \"\"\"Limits the string to a number of tokens (estimated).\"\"\"\n",
    "\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except:\n",
    "        encoding = tiktoken.encoding_for_model('gpt2')  # Fallback for others.\n",
    "\n",
    "    encoded = encoding.encode(string)\n",
    "\n",
    "    return encoding.decode(encoded[:limit])\n",
    "\n",
    "\n",
    "def openai_call(\n",
    "    prompt: str,\n",
    "    model: str = LLM_MODEL,\n",
    "    temperature: float = OPENAI_TEMPERATURE,\n",
    "    max_tokens: int = 100,\n",
    "):\n",
    "    while True:\n",
    "        try:\n",
    "            if model.lower().startswith(\"llama\"):\n",
    "                result = llm(prompt[:CTX_MAX],\n",
    "                             stop=[\"### Human\"],\n",
    "                             echo=False,\n",
    "                             temperature=0.2,\n",
    "                             top_k=40,\n",
    "                             top_p=0.95,\n",
    "                             repeat_penalty=1.05,\n",
    "                             max_tokens=200)\n",
    "                # print('\\n*****RESULT JSON DUMP*****\\n')\n",
    "                # print(json.dumps(result))\n",
    "                # print('\\n')\n",
    "                return result['choices'][0]['text'].strip()\n",
    "            elif model.lower().startswith(\"human\"):\n",
    "                return user_input_await(prompt)\n",
    "            elif not model.lower().startswith(\"gpt-\"):\n",
    "                # Use completion API\n",
    "                response = openai.Completion.create(\n",
    "                    engine=model,\n",
    "                    prompt=prompt,\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=max_tokens,\n",
    "                    top_p=1,\n",
    "                    frequency_penalty=0,\n",
    "                    presence_penalty=0,\n",
    "                )\n",
    "                return response.choices[0].text.strip()\n",
    "            else:\n",
    "                # Use 4000 instead of the real limit (4097) to give a bit of wiggle room for the encoding of roles.\n",
    "                # TODO: different limits for different models.\n",
    "\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful and educated carbon capture research consultant and an educated and helpful researcher and programmer. Answer as correctly, clearly, and concisely as possible. You give first-rate answers.\"},\n",
    "                ]\n",
    "                trimmed_prompt = limit_tokens_from_string(prompt, model, 3750 - max_tokens)\n",
    "\n",
    "                # Use chat completion API\n",
    "                messages.append({\"role\": \"user\", \"content\": trimmed_prompt})\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=max_tokens,\n",
    "                    n=1,\n",
    "                    stop=None,\n",
    "                )\n",
    "                return response.choices[0].message.content.strip()\n",
    "        except openai.error.RateLimitError:\n",
    "            print(\n",
    "                \"   *** The OpenAI API rate limit has been exceeded. Waiting 10 seconds and trying again. ***\"\n",
    "            )\n",
    "            time.sleep(10)  # Wait 10 seconds and try again\n",
    "        except openai.error.Timeout:\n",
    "            print(\n",
    "                \"   *** OpenAI API timeout occurred. Waiting 10 seconds and trying again. ***\"\n",
    "            )\n",
    "            time.sleep(10)  # Wait 10 seconds and try again\n",
    "        except openai.error.APIError:\n",
    "            print(\n",
    "                \"   *** OpenAI API error occurred. Waiting 10 seconds and trying again. ***\"\n",
    "            )\n",
    "            time.sleep(10)  # Wait 10 seconds and try again\n",
    "        except openai.error.APIConnectionError:\n",
    "            print(\n",
    "                \"   *** OpenAI API connection error occurred. Check your network settings, proxy configuration, SSL certificates, or firewall rules. Waiting 10 seconds and trying again. ***\"\n",
    "            )\n",
    "            time.sleep(10)  # Wait 10 seconds and try again\n",
    "        except openai.error.InvalidRequestError:\n",
    "            print(\n",
    "                \"   *** OpenAI API invalid request. Check the documentation for the specific API method you are calling and make sure you are sending valid and complete parameters. Waiting 10 seconds and trying again. ***\"\n",
    "            )\n",
    "            time.sleep(10)  # Wait 10 seconds and try again\n",
    "        except openai.error.ServiceUnavailableError:\n",
    "            print(\n",
    "                \"   *** OpenAI API service unavailable. Waiting 10 seconds and trying again. ***\"\n",
    "            )\n",
    "            time.sleep(10)  # Wait 10 seconds and try again\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_creation_agent(\n",
    "        objective: str, result: Dict, task_description: str, task_list: List[str]\n",
    "):\n",
    "    prompt = f\"\"\"\n",
    "You are to use the result from an execution agent to create new tasks with the following objective: {objective}.\n",
    "The last completed task has the result: \\n{result[\"data\"]}\n",
    "This result was based on this task description: {task_description}.\\n\"\"\"\n",
    "\n",
    "    if task_list:\n",
    "        prompt += f\"These are incomplete tasks: {', '.join(task_list)}\\n\"\n",
    "    prompt += \"Based on the result, return a list of tasks to be completed in order to meet the objective. \"\n",
    "    if task_list:\n",
    "        prompt += \"These new tasks must not overlap with incomplete tasks. \"\n",
    "\n",
    "    prompt += \"\"\"\n",
    "Return one task per line in your response. The result must be a numbered list in the format:\n",
    "\n",
    "#. First task\n",
    "#. Second task\n",
    "\n",
    "The number of each entry must be followed by a period. If your list is empty, write \"There are no tasks to add at this time.\"\n",
    "Unless your list is empty, do not include any headers before your numbered list or follow your numbered list with any other output.\"\"\"\n",
    "\n",
    "    print(f'\\n*****TASK CREATION AGENT PROMPT****\\n{prompt}\\n')\n",
    "    response = openai_call(prompt, max_tokens=2000)\n",
    "    print(f'\\n****TASK CREATION AGENT RESPONSE****\\n{response}\\n')\n",
    "    new_tasks = response.split('\\n')\n",
    "    new_tasks_list = []\n",
    "    for task_string in new_tasks:\n",
    "        task_parts = task_string.strip().split(\".\", 1)\n",
    "        if len(task_parts) == 2:\n",
    "            task_id = ''.join(s for s in task_parts[0] if s.isnumeric())\n",
    "            task_name = re.sub(r'[^\\w\\s_]+', '', task_parts[1]).strip()\n",
    "            if task_name.strip() and task_id.isnumeric():\n",
    "                new_tasks_list.append(task_name)\n",
    "            # print('New task created: ' + task_name)\n",
    "\n",
    "    out = [{\"task_name\": task_name} for task_name in new_tasks_list]\n",
    "    return out\n",
    "\n",
    "\n",
    "def prioritization_agent():\n",
    "    task_names = tasks_storage.get_task_names()\n",
    "    bullet_string = '\\n'\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are tasked with prioritizing the following tasks: {bullet_string + bullet_string.join(task_names)}\n",
    "Consider the ultimate objective of your team: {OBJECTIVE}.\n",
    "Tasks should be sorted from highest to lowest priority, where higher-priority tasks are those that act as pre-requisites or are more essential for meeting the objective.\n",
    "Do not remove any tasks. Return the ranked tasks as a numbered list in the format:\n",
    "\n",
    "#. First task\n",
    "#. Second task\n",
    "\n",
    "The entries must be consecutively numbered, starting with 1. The number of each entry must be followed by a period.\n",
    "Do not include any headers before your ranked list or follow your list with any other output.\"\"\"\n",
    "\n",
    "    print(f'\\n****TASK PRIORITIZATION AGENT PROMPT****\\n{prompt}\\n')\n",
    "    response = openai_call(prompt, max_tokens=2000)\n",
    "    print(f'\\n****TASK PRIORITIZATION AGENT RESPONSE****\\n{response}\\n')\n",
    "    if not response:\n",
    "        print('Received empty response from priotritization agent. Keeping task list unchanged.')\n",
    "        return\n",
    "    new_tasks = response.split(\"\\n\") if \"\\n\" in response else [response]\n",
    "    new_tasks_list = []\n",
    "    for task_string in new_tasks:\n",
    "        task_parts = task_string.strip().split(\".\", 1)\n",
    "        if len(task_parts) == 2:\n",
    "            task_id = ''.join(s for s in task_parts[0] if s.isnumeric())\n",
    "            task_name = re.sub(r'[^\\w\\s_]+', '', task_parts[1]).strip()\n",
    "            if task_name.strip():\n",
    "                new_tasks_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
    "\n",
    "    return new_tasks_list\n",
    "\n",
    "\n",
    "# Execute a task based on the objective and five previous tasks\n",
    "def execution_agent(objective: str, task: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes a task based on the given objective and previous context.\n",
    "\n",
    "    Args:\n",
    "        objective (str): The objective or goal for the AI to perform the task.\n",
    "        task (str): The task to be executed by the AI.\n",
    "\n",
    "    Returns:\n",
    "        str: The response generated by the AI for the given task.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    context = context_agent(query=objective, top_results_num=5)\n",
    "    # print(\"\\n****RELEVANT CONTEXT****\\n\")\n",
    "    # print(context)\n",
    "    # print('')\n",
    "    prompt = f'Perform one task based on the following objective: {objective}.\\n'\n",
    "    if context:\n",
    "        prompt += 'Take into account these previously completed tasks:' + '\\n'.join(context)\n",
    "    prompt += f'''\n",
    "    Your task: {task}\n",
    "\n",
    "    Either use the best of your knowledge to return a first-rate response in normal text, or if it's more appropriate to return top facts to a web search query in response, return only the JSON output with no explanation or conversation:\n",
    "    {{\n",
    "        \"search\": \"<search query>\"\n",
    "    }}\n",
    "\n",
    "    Response:\n",
    "    '''\n",
    "    res = openai_call(prompt, max_tokens=2000)\n",
    "    try:\n",
    "        res = json.loads(res)\n",
    "        print(\"***SEARCHING WEB***\")\n",
    "        try:\n",
    "            search_query = res[\"search\"]\n",
    "            return str(search_web_for_facts(search_query))\n",
    "        except:\n",
    "            return \"Response failed. Might need to try again!\"\n",
    "    except:\n",
    "        print(\"***USING KNOWLEDGE***\")\n",
    "        return res\n",
    "\n",
    "# Get the top n completed tasks for the objective\n",
    "def context_agent(query: str, top_results_num: int):\n",
    "    \"\"\"\n",
    "    Retrieves context for a given query from an index of tasks.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query or objective for retrieving context.\n",
    "        top_results_num (int): The number of top results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tasks as context for the given query, sorted by relevance.\n",
    "\n",
    "    \"\"\"\n",
    "    results = results_storage.query(query=query, top_results_num=top_results_num)\n",
    "    # print(\"****RESULTS****\")\n",
    "    # print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1m\n",
      "*****OBJECTIVE*****\n",
      "\u001b[0m\u001b[0m\n",
      "Suggest novel and actionable research designs and solutions that could potentially carbon capture 1 Gt of CO2 per year ASAP. Your constraints are 1) you can only leverage knowledge on the web to reason your way to potentially impactful hypotheses, 2) this is independent research work with only 1 human collaborator responsible for conducting physical experiments, and 3) you cannot seek outside funding and must work to minimize the budget but maximize impact.\n",
      "\u001b[93m\u001b[1m\n",
      "Initial task:\u001b[0m\u001b[0m Develop a research strategy to achieve the objective. \n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[94m\\033[1m\" + \"\\n*****OBJECTIVE*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "print(f\"{OBJECTIVE}\")\n",
    "\n",
    "if not JOIN_EXISTING_OBJECTIVE:\n",
    "    print(\"\\033[93m\\033[1m\" + \"\\nInitial task:\" + \"\\033[0m\\033[0m\" + f\" {INITIAL_TASK}\")\n",
    "else:\n",
    "    print(\"\\033[93m\\033[1m\" + f\"\\nJoining to help the objective\" + \"\\033[0m\\033[0m\")\n",
    "\n",
    "# Add the initial task if starting new objective\n",
    "if not JOIN_EXISTING_OBJECTIVE:\n",
    "    initial_task = {\n",
    "        \"task_id\": tasks_storage.next_task_id(),\n",
    "        \"task_name\": INITIAL_TASK\n",
    "    }\n",
    "    tasks_storage.append(initial_task)\n",
    "\n",
    "def user_interaction():\n",
    "    while True:\n",
    "        print(\"\\033[96m\\033[1m\" + \"\\n*****USER INPUT*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "        print(\"Select an option:\")\n",
    "        print(\"1. Modify tasks\")\n",
    "        print(\"2. Proceed\")\n",
    "        print(\"3. Stop and exit\")\n",
    "        user_input = input(\"Enter the number corresponding to your choice: \")\n",
    "\n",
    "        if user_input == \"1\":\n",
    "            return \"modify_tasks\"\n",
    "        elif user_input == \"2\":\n",
    "            return \"proceed\"\n",
    "        elif user_input == \"3\":\n",
    "            return \"stop\"\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "def main():\n",
    "    loop = True\n",
    "    while loop:\n",
    "        # As long as there are tasks in the storage...\n",
    "        if not tasks_storage.is_empty():\n",
    "            # Print the task list\n",
    "            print(\"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "            for t in tasks_storage.get_task_names():\n",
    "                print(\" • \" + str(t))\n",
    "\n",
    "            # Step 1: Pull the first incomplete task\n",
    "            task = tasks_storage.popleft()\n",
    "            print(\"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "            print(str(task[\"task_name\"]))\n",
    "\n",
    "            # Send to execution function to complete the task based on the context\n",
    "            result = execution_agent(OBJECTIVE, str(task[\"task_name\"]))\n",
    "            print(\"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "            print(result)\n",
    "\n",
    "            # Step 2: Enrich result and store in the results storage\n",
    "            # This is where you should enrich the result if needed\n",
    "            enriched_result = {\n",
    "                \"data\": result\n",
    "            }\n",
    "            # extract the actual result from the dictionary\n",
    "            # since we don't do enrichment currently\n",
    "            # vector = enriched_result[\"data\"]\n",
    "\n",
    "            result_id = f\"result_{task['task_id']}\"\n",
    "\n",
    "            results_storage.add(task, result, result_id)\n",
    "\n",
    "            # Step 3: Create new tasks and re-prioritize task list\n",
    "            # only the main instance in cooperative mode does that\n",
    "            new_tasks = task_creation_agent(\n",
    "                OBJECTIVE,\n",
    "                enriched_result,\n",
    "                task[\"task_name\"],\n",
    "                tasks_storage.get_task_names(),\n",
    "            )\n",
    "\n",
    "            print('Adding new tasks to task_storage')\n",
    "            for new_task in new_tasks:\n",
    "                new_task.update({\"task_id\": tasks_storage.next_task_id()})\n",
    "                print(str(new_task))\n",
    "                tasks_storage.append(new_task)\n",
    "\n",
    "            if not JOIN_EXISTING_OBJECTIVE:\n",
    "                prioritized_tasks = prioritization_agent()\n",
    "                if prioritized_tasks:\n",
    "                    tasks_storage.replace(prioritized_tasks)\n",
    "\n",
    "            # # Sleep a bit before checking the task list again\n",
    "            # time.sleep(5)\n",
    "\n",
    "            user_choice = user_interaction()\n",
    "            if user_choice == \"modify_tasks\":\n",
    "                new_task_name = input(\"Enter the new task to be added: \")\n",
    "                new_task = {\n",
    "                    \"task_id\": tasks_storage.next_task_id(),\n",
    "                    \"task_name\": new_task_name\n",
    "                }\n",
    "                tasks_storage.append(new_task)\n",
    "                prioritization_agent()\n",
    "            elif user_choice == \"stop\":\n",
    "                break\n",
    "        else:\n",
    "            print('Done.')\n",
    "            loop = False\n",
    "            \n",
    "            if debug_full_text:\n",
    "                sys.stdout = original_stdout\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      " • Develop a research strategy to achieve the objective. \n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "Develop a research strategy to achieve the objective. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***USING KNOWLEDGE***\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "To achieve the objective of carbon capturing 1 Gt of CO2 per year ASAP, the following research strategy can be implemented:\n",
      "\n",
      "1. Identify and prioritize potential carbon capture technologies: Conduct a comprehensive review of existing carbon capture technologies and identify the most promising ones in terms of scalability, efficiency, and cost-effectiveness.\n",
      "\n",
      "2. Conduct feasibility studies: Evaluate the feasibility of implementing the identified carbon capture technologies in different industries and sectors. Consider factors such as infrastructure requirements, energy consumption, and potential environmental impacts.\n",
      "\n",
      "3. Optimize carbon capture processes: Collaborate with the human collaborator to design and conduct physical experiments to optimize the identified carbon capture technologies. Focus on improving capture efficiency, reducing energy requirements, and exploring novel materials or catalysts.\n",
      "\n",
      "4. Explore integration opportunities: Investigate opportunities for integrating carbon capture technologies with existing industrial processes or infrastructure. This could include capturing CO2 emissions from power plants, cement factories, or other large-scale emission sources.\n",
      "\n",
      "5. Develop pilot projects: Design and implement small-scale pilot projects to test the feasibility and effectiveness of the optimized carbon capture technologies. These projects should aim to capture a significant amount of CO2 emissions and provide valuable data for further optimization.\n",
      "\n",
      "6. Collaborate with industry partners: Seek collaborations with industry partners who are willing to implement and scale up the carbon capture technologies. This can help accelerate the deployment of the technologies and ensure their integration into existing processes.\n",
      "\n",
      "7. Continuously monitor and improve: Establish a monitoring system to track the performance and environmental impact of the implemented carbon capture technologies. Use the data collected to identify areas for improvement and optimize the processes further.\n",
      "\n",
      "By following this research strategy, it is possible to develop novel and actionable research designs and solutions that can potentially capture 1 Gt of CO2 per year, while working within the constraints of independent research with limited funding.\n",
      "\n",
      "*****TASK CREATION AGENT PROMPT****\n",
      "\n",
      "You are to use the result from an execution agent to create new tasks with the following objective: Suggest novel and actionable research designs and solutions that could potentially carbon capture 1 Gt of CO2 per year ASAP. Your constraints are 1) you can only leverage knowledge on the web to reason your way to potentially impactful hypotheses, 2) this is independent research work with only 1 human collaborator responsible for conducting physical experiments, and 3) you cannot seek outside funding and must work to minimize the budget but maximize impact..\n",
      "The last completed task has the result: \n",
      "To achieve the objective of carbon capturing 1 Gt of CO2 per year ASAP, the following research strategy can be implemented:\n",
      "\n",
      "1. Identify and prioritize potential carbon capture technologies: Conduct a comprehensive review of existing carbon capture technologies and identify the most promising ones in terms of scalability, efficiency, and cost-effectiveness.\n",
      "\n",
      "2. Conduct feasibility studies: Evaluate the feasibility of implementing the identified carbon capture technologies in different industries and sectors. Consider factors such as infrastructure requirements, energy consumption, and potential environmental impacts.\n",
      "\n",
      "3. Optimize carbon capture processes: Collaborate with the human collaborator to design and conduct physical experiments to optimize the identified carbon capture technologies. Focus on improving capture efficiency, reducing energy requirements, and exploring novel materials or catalysts.\n",
      "\n",
      "4. Explore integration opportunities: Investigate opportunities for integrating carbon capture technologies with existing industrial processes or infrastructure. This could include capturing CO2 emissions from power plants, cement factories, or other large-scale emission sources.\n",
      "\n",
      "5. Develop pilot projects: Design and implement small-scale pilot projects to test the feasibility and effectiveness of the optimized carbon capture technologies. These projects should aim to capture a significant amount of CO2 emissions and provide valuable data for further optimization.\n",
      "\n",
      "6. Collaborate with industry partners: Seek collaborations with industry partners who are willing to implement and scale up the carbon capture technologies. This can help accelerate the deployment of the technologies and ensure their integration into existing processes.\n",
      "\n",
      "7. Continuously monitor and improve: Establish a monitoring system to track the performance and environmental impact of the implemented carbon capture technologies. Use the data collected to identify areas for improvement and optimize the processes further.\n",
      "\n",
      "By following this research strategy, it is possible to develop novel and actionable research designs and solutions that can potentially capture 1 Gt of CO2 per year, while working within the constraints of independent research with limited funding.\n",
      "This result was based on this task description: Develop a research strategy to achieve the objective. .\n",
      "Based on the result, return a list of tasks to be completed in order to meet the objective. \n",
      "Return one task per line in your response. The result must be a numbered list in the format:\n",
      "\n",
      "#. First task\n",
      "#. Second task\n",
      "\n",
      "The number of each entry must be followed by a period. If your list is empty, write \"There are no tasks to add at this time.\"\n",
      "Unless your list is empty, do not include any headers before your numbered list or follow your numbered list with any other output.\n",
      "\n",
      "\n",
      "****TASK CREATION AGENT RESPONSE****\n",
      "1. Conduct a comprehensive review of existing carbon capture technologies and identify the most promising ones in terms of scalability, efficiency, and cost-effectiveness.\n",
      "2. Evaluate the feasibility of implementing the identified carbon capture technologies in different industries and sectors, considering factors such as infrastructure requirements, energy consumption, and potential environmental impacts.\n",
      "3. Collaborate with the human collaborator to design and conduct physical experiments to optimize the identified carbon capture technologies, focusing on improving capture efficiency, reducing energy requirements, and exploring novel materials or catalysts.\n",
      "4. Investigate opportunities for integrating carbon capture technologies with existing industrial processes or infrastructure, such as capturing CO2 emissions from power plants, cement factories, or other large-scale emission sources.\n",
      "5. Design and implement small-scale pilot projects to test the feasibility and effectiveness of the optimized carbon capture technologies, aiming to capture a significant amount of CO2 emissions and provide valuable data for further optimization.\n",
      "6. Seek collaborations with industry partners who are willing to implement and scale up the carbon capture technologies, accelerating the deployment of the technologies and ensuring their integration into existing processes.\n",
      "7. Establish a monitoring system to track the performance and environmental impact of the implemented carbon capture technologies, using the data collected to identify areas for improvement and optimize the processes further.\n",
      "\n",
      "Note: This list of tasks is based on the previous result and provides a step-by-step approach to achieving the objective of carbon capturing 1 Gt of CO2 per year ASAP, while considering the given constraints.\n",
      "\n",
      "Adding new tasks to task_storage\n",
      "{'task_name': 'Conduct a comprehensive review of existing carbon capture technologies and identify the most promising ones in terms of scalability efficiency and costeffectiveness', 'task_id': 2}\n",
      "{'task_name': 'Evaluate the feasibility of implementing the identified carbon capture technologies in different industries and sectors considering factors such as infrastructure requirements energy consumption and potential environmental impacts', 'task_id': 3}\n",
      "{'task_name': 'Collaborate with the human collaborator to design and conduct physical experiments to optimize the identified carbon capture technologies focusing on improving capture efficiency reducing energy requirements and exploring novel materials or catalysts', 'task_id': 4}\n",
      "{'task_name': 'Investigate opportunities for integrating carbon capture technologies with existing industrial processes or infrastructure such as capturing CO2 emissions from power plants cement factories or other largescale emission sources', 'task_id': 5}\n",
      "{'task_name': 'Design and implement smallscale pilot projects to test the feasibility and effectiveness of the optimized carbon capture technologies aiming to capture a significant amount of CO2 emissions and provide valuable data for further optimization', 'task_id': 6}\n",
      "{'task_name': 'Seek collaborations with industry partners who are willing to implement and scale up the carbon capture technologies accelerating the deployment of the technologies and ensuring their integration into existing processes', 'task_id': 7}\n",
      "{'task_name': 'Establish a monitoring system to track the performance and environmental impact of the implemented carbon capture technologies using the data collected to identify areas for improvement and optimize the processes further', 'task_id': 8}\n",
      "\n",
      "****TASK PRIORITIZATION AGENT PROMPT****\n",
      "\n",
      "You are tasked with prioritizing the following tasks: \n",
      "Conduct a comprehensive review of existing carbon capture technologies and identify the most promising ones in terms of scalability efficiency and costeffectiveness\n",
      "Evaluate the feasibility of implementing the identified carbon capture technologies in different industries and sectors considering factors such as infrastructure requirements energy consumption and potential environmental impacts\n",
      "Collaborate with the human collaborator to design and conduct physical experiments to optimize the identified carbon capture technologies focusing on improving capture efficiency reducing energy requirements and exploring novel materials or catalysts\n",
      "Investigate opportunities for integrating carbon capture technologies with existing industrial processes or infrastructure such as capturing CO2 emissions from power plants cement factories or other largescale emission sources\n",
      "Design and implement smallscale pilot projects to test the feasibility and effectiveness of the optimized carbon capture technologies aiming to capture a significant amount of CO2 emissions and provide valuable data for further optimization\n",
      "Seek collaborations with industry partners who are willing to implement and scale up the carbon capture technologies accelerating the deployment of the technologies and ensuring their integration into existing processes\n",
      "Establish a monitoring system to track the performance and environmental impact of the implemented carbon capture technologies using the data collected to identify areas for improvement and optimize the processes further\n",
      "Consider the ultimate objective of your team: Suggest novel and actionable research designs and solutions that could potentially carbon capture 1 Gt of CO2 per year ASAP. Your constraints are 1) you can only leverage knowledge on the web to reason your way to potentially impactful hypotheses, 2) this is independent research work with only 1 human collaborator responsible for conducting physical experiments, and 3) you cannot seek outside funding and must work to minimize the budget but maximize impact..\n",
      "Tasks should be sorted from highest to lowest priority, where higher-priority tasks are those that act as pre-requisites or are more essential for meeting the objective.\n",
      "Do not remove any tasks. Return the ranked tasks as a numbered list in the format:\n",
      "\n",
      "#. First task\n",
      "#. Second task\n",
      "\n",
      "The entries must be consecutively numbered, starting with 1. The number of each entry must be followed by a period.\n",
      "Do not include any headers before your ranked list or follow your list with any other output.\n",
      "\n",
      "\n",
      "****TASK PRIORITIZATION AGENT RESPONSE****\n",
      "1. Conduct a comprehensive review of existing carbon capture technologies and identify the most promising ones in terms of scalability, efficiency, and cost-effectiveness.\n",
      "2. Evaluate the feasibility of implementing the identified carbon capture technologies in different industries and sectors considering factors such as infrastructure requirements, energy consumption, and potential environmental impacts.\n",
      "3. Investigate opportunities for integrating carbon capture technologies with existing industrial processes or infrastructure such as capturing CO2 emissions from power plants, cement factories, or other large-scale emission sources.\n",
      "4. Collaborate with the human collaborator to design and conduct physical experiments to optimize the identified carbon capture technologies, focusing on improving capture efficiency, reducing energy requirements, and exploring novel materials or catalysts.\n",
      "5. Design and implement small-scale pilot projects to test the feasibility and effectiveness of the optimized carbon capture technologies, aiming to capture a significant amount of CO2 emissions and provide valuable data for further optimization.\n",
      "6. Establish a monitoring system to track the performance and environmental impact of the implemented carbon capture technologies, using the data collected to identify areas for improvement and optimize the processes further.\n",
      "7. Seek collaborations with industry partners who are willing to implement and scale up the carbon capture technologies, accelerating the deployment of the technologies and ensuring their integration into existing processes.\n",
      "\n",
      "Note: While the ultimate objective is to suggest novel and actionable research designs and solutions to capture 1 Gt of CO2 per year ASAP, the prioritized tasks focus on building a strong foundation of knowledge, feasibility assessment, optimization, and pilot testing before scaling up.\n",
      "\n",
      "\u001b[96m\u001b[1m\n",
      "*****USER INPUT*****\n",
      "\u001b[0m\u001b[0m\n",
      "Select an option:\n",
      "1. Modify tasks\n",
      "2. Proceed\n",
      "3. Stop and exit\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      " • Conduct a comprehensive review of existing carbon capture technologies and identify the most promising ones in terms of scalability efficiency and costeffectiveness\n",
      " • Evaluate the feasibility of implementing the identified carbon capture technologies in different industries and sectors considering factors such as infrastructure requirements energy consumption and potential environmental impacts\n",
      " • Investigate opportunities for integrating carbon capture technologies with existing industrial processes or infrastructure such as capturing CO2 emissions from power plants cement factories or other largescale emission sources\n",
      " • Collaborate with the human collaborator to design and conduct physical experiments to optimize the identified carbon capture technologies focusing on improving capture efficiency reducing energy requirements and exploring novel materials or catalysts\n",
      " • Design and implement smallscale pilot projects to test the feasibility and effectiveness of the optimized carbon capture technologies aiming to capture a significant amount of CO2 emissions and provide valuable data for further optimization\n",
      " • Establish a monitoring system to track the performance and environmental impact of the implemented carbon capture technologies using the data collected to identify areas for improvement and optimize the processes further\n",
      " • Seek collaborations with industry partners who are willing to implement and scale up the carbon capture technologies accelerating the deployment of the technologies and ensuring their integration into existing processes\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "Conduct a comprehensive review of existing carbon capture technologies and identify the most promising ones in terms of scalability efficiency and costeffectiveness\n",
      "***SEARCHING WEB***\n",
      "****Starting web search for facts with this search query: existing carbon capture technologies****\n",
      "****Web search given search keywords****\n",
      "query:  existing carbon capture technologies\n",
      "already searched query!\n",
      "****Reading type 1: filtering unlikely relevant sources based on title and body****\n",
      "already filtered query!\n",
      "****Reading type 2 & 3: filtering via skimming****\n",
      "query  1 rating_source_idx 0 Skimming url: https://www.sciencedirect.com/science/article/pii/S1876610217320520\n",
      "URL or text already visited!\n",
      "****Extract facts****\n",
      "****Rerank facts.txt file based on relevancy****\n",
      "['Established CO2 capture technologies such as amine scrubbing consume significant amounts of energy, reducing power plant efficiency by around 10%pts and contributing to increases in the cost of electricity production by up to 80%.']\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "['Established CO2 capture technologies such as amine scrubbing consume significant amounts of energy, reducing power plant efficiency by around 10%pts and contributing to increases in the cost of electricity production by up to 80%.']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected metadata value to be a str, int, or float, got ['Established CO2 capture technologies such as amine scrubbing consume significant amounts of energy, reducing power plant efficiency by around 10%pts and contributing to increases in the cost of electricity production by up to 80%.']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[9], line 66\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m# extract the actual result from the dictionary\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m# since we don't do enrichment currently\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m# vector = enriched_result[\"data\"]\u001b[39;00m\n\u001b[0;32m     64\u001b[0m result_id \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresult_\u001b[39m\u001b[39m{\u001b[39;00mtask[\u001b[39m'\u001b[39m\u001b[39mtask_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 66\u001b[0m results_storage\u001b[39m.\u001b[39;49madd(task, result, result_id)\n\u001b[0;32m     68\u001b[0m \u001b[39m# Step 3: Create new tasks and re-prioritize task list\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39m# only the main instance in cooperative mode does that\u001b[39;00m\n\u001b[0;32m     70\u001b[0m new_tasks \u001b[39m=\u001b[39m task_creation_agent(\n\u001b[0;32m     71\u001b[0m     OBJECTIVE,\n\u001b[0;32m     72\u001b[0m     enriched_result,\n\u001b[0;32m     73\u001b[0m     task[\u001b[39m\"\u001b[39m\u001b[39mtask_name\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     74\u001b[0m     tasks_storage\u001b[39m.\u001b[39mget_task_names(),\n\u001b[0;32m     75\u001b[0m )\n",
      "Cell \u001b[1;32mIn[7], line 121\u001b[0m, in \u001b[0;36mDefaultResultsStorage.add\u001b[1;34m(self, task, result, result_id)\u001b[0m\n\u001b[0;32m    117\u001b[0m embeddings \u001b[39m=\u001b[39m llm_embed\u001b[39m.\u001b[39membed(result) \u001b[39mif\u001b[39;00m LLM_MODEL\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mllama\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    119\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollection\u001b[39m.\u001b[39mget(ids\u001b[39m=\u001b[39m[result_id], include\u001b[39m=\u001b[39m[])[\u001b[39m\"\u001b[39m\u001b[39mids\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    120\u001b[0m ):  \u001b[39m# Check if the result already exists\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollection\u001b[39m.\u001b[39;49mupdate(\n\u001b[0;32m    122\u001b[0m         ids\u001b[39m=\u001b[39;49mresult_id,\n\u001b[0;32m    123\u001b[0m         embeddings\u001b[39m=\u001b[39;49membeddings,\n\u001b[0;32m    124\u001b[0m         documents\u001b[39m=\u001b[39;49mresult,\n\u001b[0;32m    125\u001b[0m         metadatas\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mtask\u001b[39;49m\u001b[39m\"\u001b[39;49m: task[\u001b[39m\"\u001b[39;49m\u001b[39mtask_name\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mresult\u001b[39;49m\u001b[39m\"\u001b[39;49m: result},\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    127\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollection\u001b[39m.\u001b[39madd(\n\u001b[0;32m    129\u001b[0m         ids\u001b[39m=\u001b[39mresult_id,\n\u001b[0;32m    130\u001b[0m         embeddings\u001b[39m=\u001b[39membeddings,\n\u001b[0;32m    131\u001b[0m         documents\u001b[39m=\u001b[39mresult,\n\u001b[0;32m    132\u001b[0m         metadatas\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m: task[\u001b[39m\"\u001b[39m\u001b[39mtask_name\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m\"\u001b[39m: result},\n\u001b[0;32m    133\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\1kevi\\Desktop\\projects\\Research\\autoscious-carbon-capture\\venv\\lib\\site-packages\\chromadb\\api\\models\\Collection.py:242\u001b[0m, in \u001b[0;36mCollection.update\u001b[1;34m(self, ids, embeddings, metadatas, documents)\u001b[0m\n\u001b[0;32m    240\u001b[0m ids \u001b[39m=\u001b[39m validate_ids(maybe_cast_one_to_many(ids))\n\u001b[0;32m    241\u001b[0m embeddings \u001b[39m=\u001b[39m maybe_cast_one_to_many(embeddings) \u001b[39mif\u001b[39;00m embeddings \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m metadatas \u001b[39m=\u001b[39m validate_metadatas(maybe_cast_one_to_many(metadatas)) \u001b[39mif\u001b[39;00m metadatas \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m documents \u001b[39m=\u001b[39m maybe_cast_one_to_many(documents) \u001b[39mif\u001b[39;00m documents \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m# Must update one of embeddings, metadatas, or documents\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\1kevi\\Desktop\\projects\\Research\\autoscious-carbon-capture\\venv\\lib\\site-packages\\chromadb\\api\\types.py:107\u001b[0m, in \u001b[0;36mvalidate_metadatas\u001b[1;34m(metadatas)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected metadatas to be a list, got \u001b[39m\u001b[39m{\u001b[39;00mmetadatas\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[39mfor\u001b[39;00m metadata \u001b[39min\u001b[39;00m metadatas:\n\u001b[1;32m--> 107\u001b[0m     validate_metadata(metadata)\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m metadatas\n",
      "File \u001b[1;32mc:\\Users\\1kevi\\Desktop\\projects\\Research\\autoscious-carbon-capture\\venv\\lib\\site-packages\\chromadb\\api\\types.py:98\u001b[0m, in \u001b[0;36mvalidate_metadata\u001b[1;34m(metadata)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected metadata key to be a str, got \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, (\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m)):\n\u001b[1;32m---> 98\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected metadata value to be a str, int, or float, got \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m metadata\n",
      "\u001b[1;31mValueError\u001b[0m: Expected metadata value to be a str, int, or float, got ['Established CO2 capture technologies such as amine scrubbing consume significant amounts of energy, reducing power plant efficiency by around 10%pts and contributing to increases in the cost of electricity production by up to 80%.']"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
