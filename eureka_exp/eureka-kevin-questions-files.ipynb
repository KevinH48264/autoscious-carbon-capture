{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import chat_openai\n",
    "import numpy as np \n",
    "import json\n",
    "import logging \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import openai\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import time \n",
    "import types\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = '''\n",
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
    "\n",
    "Goal\n",
    "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. \n",
    "\n",
    "Metric\n",
    "Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n",
    "\n",
    "Submission File Format\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "Id,SalePrice\n",
    "1461,169000.1\n",
    "1462,187724.1233\n",
    "1463,175221\n",
    "etc.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_file_directory = \"agent_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_progress = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurriculumAgent():\n",
    "    def __init__(self, goal=\"\", memory=[], completed_tasks=[], failed_tasks=[], files=\"\", saved_notes=\"\"):\n",
    "        self.goal = goal\n",
    "        # self.memory = memory\n",
    "        self.completed_tasks = completed_tasks\n",
    "        self.failed_tasks = failed_tasks\n",
    "        # self.files = files\n",
    "        # self.saved_notes = saved_notes\n",
    "\n",
    "        # The crux is a Q&A process\n",
    "        # Problem with this approach is you still have to deal with searching multiple times, and continuing to search or not. Approach: Or maybe if you search and you don't have the answer, that's a bad thing to search and you need to go more specific / ask a different question!\n",
    "        self.system_prompt_automatic_curriculum = f'''You are a helpful assistant that asks questions to help me decide the next immediate question to answer on the computer. My ultimate goal is to discover as many useful pieces of information as possible, answer as many questions as possible, and become the best researcher in the world.\n",
    "\n",
    "        Goal: {self.goal}\n",
    "\n",
    "        I will give you the following information:\n",
    "        Knowledge base files: these are information blocks that I have and can build upon as I answer more questions, almost like theorems that have been validated.\n",
    "        Completed tasks so far: ...\n",
    "        Failed tasks that are too hard: ...\n",
    "\n",
    "        1) You should act as a mentor and guide me to the next question based on my current learning progress.\n",
    "        2) Please be very specific about what question I need to answer.\n",
    "        3) The next question should follow a clear format, such as \"What do other papers say about [topic]\", \"What are the problems with [approach]\", \"How can I solve this [problem]\", \"Can results from [topic 1] be applied to [topic 2]?\", \"What are the similarities between [topic 1] for success and [topic 2]\" , \"What's significant about this paper: [paper]?\", \"What does [topic] mean?\", etc. It should be a single question to collect useful information on. Do not propose multiple questions at the same time. Do not mention anything else. \n",
    "        4) The next question should not be too hard since the internet and I may not contain the full answer in a single article or have learned enough information to complete it yet. \n",
    "        5) The next question should be novel and interesting based on my current learning progress. I should look for rare and potentially useful pieces of information, upgrade my saved notes using better information, and discover new things. I should not be doing the same thing over and over again.\n",
    "        6) I may sometimes need to repeat some questions or variations of the question if I need to collect more information to answer more difficult question. Only repeat questions if necessary. \n",
    "        7) I want to explore the world and discover new things. I don’t want to stay in my current state for too long. \n",
    "        8) Questions that require information beyond another person's ability to theoretically verify and reason if completed or correct should be avoided. For instance, \"what else is there on the website?\" and \"what images and tables are on the website\" are not ideal since they require visual confirmation from the screen. All the testing, coding, and asking other people questions should be avoided. Do not propose a question with these keywords. You should only respond in the format as described below:\n",
    "        \n",
    "        RESPONSE FORMAT: \n",
    "        Reasoning: Based on the information I listed above, do reasoning about what the next question should be. \n",
    "        Question: The next question. \n",
    "        \n",
    "        Here’s an example response: \n",
    "        Reasoning: We know the we have a sword and we know there's fire, and fire lights things on fire. Therefore, we could try to make a firesword.\n",
    "        Question: Could we make a firesword?\n",
    "'''\n",
    "\n",
    "        # TODO: This is optional, might be useful, but to focus on a system prompt of asking questions and answering questions.\n",
    "        # System 2: this is a more scoped down version where we have the focus be on only answering questions -- reading and analyzing information & asking questions. No action items. \n",
    "        # The current above system 1 is better for self-driving labs type of work where there are going to be more tasks.\n",
    "\n",
    "    def get_exploration_progress(self, completed_tasks, failed_tasks):\n",
    "        # TODO: this should contain inventory of where we're at now and what files we have / memory stream\n",
    "        return '''Completed tasks: None, Failed tasks: None'''\n",
    "\n",
    "    def propose_next_question(self, skills, exploration_progress):\n",
    "        '''\n",
    "        This function decomposes a goal into tasks\n",
    "        '''        \n",
    "        user_prompt = \"\"\n",
    "        observation = {\n",
    "            # \"memory\": f\"Memory: {self.memory}\\n\\n\",\n",
    "            \"knowledge_base_files\": f\"Knowledge base files: {skills}\\n\\n\",\n",
    "            # \"saved_notes\": f\"Saved notes: {self.saved_notes}\\n\\n\",\n",
    "            \"completed_tasks\": f\"Completed tasks so far: {self.completed_tasks}\\n\\n\",\n",
    "            \"failed_tasks\": f\"Failed tasks that are too hard: {self.failed_tasks}\\n\\n\",\n",
    "        } # TODO: I don't think I'm even using saved notes\n",
    "        user_prompt += \"\".join(observation.values())\n",
    "        \n",
    "        print(\"System prompt for generating curriculum: \\n\", self.system_prompt_automatic_curriculum, \"\\n User prompt: \", user_prompt)\n",
    "        next_question_response = chat_openai(user_prompt, system_prompt=self.system_prompt_automatic_curriculum)[0]['content']\n",
    "        print(\"Response: \", next_question_response)\n",
    "        next_question = self.parse_message(next_question_response)[\"next_question\"]\n",
    "        return next_question\n",
    "\n",
    "    def get_completed_tasks():\n",
    "        pass\n",
    "\n",
    "    def get_failed_tasks():\n",
    "        pass\n",
    "\n",
    "    def add_completed_task(self, task):\n",
    "        self.completed_tasks.append(task)\n",
    "\n",
    "    def add_failed_task(self, task):\n",
    "        self.failed_tasks.append(task)\n",
    "\n",
    "    def parse_message(self, message):\n",
    "        question = \"\"\n",
    "        for line in message.split(\"\\n\"):\n",
    "            if line.startswith(\"Question:\"):\n",
    "                question = line[9:].strip()\n",
    "        assert question, \"Question not found in Curriculum Agent response\"\n",
    "        return {\"next_question\": question}\n",
    "\n",
    "# hardcoded\n",
    "files = '''train.csv - the training set\n",
    "test.csv - the test set\n",
    "data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\n",
    "sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\n",
    "data_fields.txt - a brief version of what you'll find in the data description file.\n",
    "'''\n",
    "curriculum_agent = CurriculumAgent(goal=goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available functions: \n",
      " {'read_file': <bound method SkillManager.read_file of <__main__.SkillManager object at 0x0000024A499A7A10>>, 'write_file': <bound method SkillManager.write_file of <__main__.SkillManager object at 0x0000024A499A7A10>>, 'web_search': <bound method SkillManager.web_search of <__main__.SkillManager object at 0x0000024A499A7A10>>, 'think': <bound method SkillManager.think of <__main__.SkillManager object at 0x0000024A499A7A10>>} \n",
      "\n",
      "Functions [{'name': 'read_file', 'description': 'Get the text from the file', 'parameters': {'type': 'object', 'properties': {'file_name': {'type': 'string', 'description': 'the complete file name and extension, e.g. abc.txt'}}, 'required': ['file_name']}}, {'name': 'write_file', 'description': 'Write text to a file', 'parameters': {'type': 'object', 'properties': {'file_name': {'type': 'string', 'description': 'the complete file name and extension, e.g. abc.txt'}, 'text': {'type': 'string', 'description': 'the text to write to the file'}}, 'required': ['file_name', 'text']}}, {'name': 'web_search', 'description': \"Given a prompt, I'll return back my web search information about it\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Tell me what to search about'}}, 'required': ['query']}}, {'name': 'think', 'description': \"Given a prompt, I'll return back my thoughts on it.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Tell me what to think about'}}, 'required': ['query']}}] \n",
      "\n",
      "Available files: \n",
      " ['train.csv - the training set', 'test.csv - the test set', 'data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here', 'sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms', \"data_fields.txt - a brief version of what you'll find in the data description file.\"]\n"
     ]
    }
   ],
   "source": [
    "class SkillManager():\n",
    "    # Additional skills to be added: await bot.findsProblem, await bot.findsInterestingInformation, await bot.findSolution or something like that\n",
    "\n",
    "    def __init__(self):\n",
    "        self.READ_MAX_CHAR_SIZE = 2500\n",
    "        self.functions = [\n",
    "            {\n",
    "                \"name\": \"read_file\",\n",
    "                \"description\": \"Get the text from the file\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"file_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"the complete file name and extension, e.g. abc.txt\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"file_name\"],            \n",
    "                }\n",
    "            }, \n",
    "            {\n",
    "                \"name\": \"write_file\",\n",
    "                \"description\": \"Write text to a file\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"file_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"the complete file name and extension, e.g. abc.txt\"\n",
    "                        },\n",
    "                        \"text\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"the text to write to the file\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"file_name\", \"text\"],            \n",
    "                }\n",
    "            }, \n",
    "            {\n",
    "                \"name\": \"web_search\",\n",
    "                \"description\": \"Given a prompt, I'll return back my web search information about it\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Tell me what to search about\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"],            \n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"think\",\n",
    "                \"description\": \"Given a prompt, I'll return back my thoughts on it.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Tell me what to think about\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"],            \n",
    "                }\n",
    "            },\n",
    "            # {\n",
    "            #     \"name\": \"num_children\",\n",
    "            #     \"description\": \"This paper talks about how many girls and boys are in this family\",\n",
    "            #     \"parameters\": {\n",
    "            #         \"type\": \"object\",\n",
    "            #         \"properties\": {},\n",
    "            #         \"required\": [],\n",
    "            #     },\n",
    "            # },\n",
    "            \n",
    "            # {\n",
    "            #     \"name\": \"content_in_data_txt\",\n",
    "            #     \"description\": \"I know the information in data.txt\",\n",
    "            #     \"parameters\": {\n",
    "            #         \"type\": \"object\",\n",
    "            #         \"properties\": {},\n",
    "            #         \"required\": [],\n",
    "            #     },\n",
    "            # }\n",
    "            # {'name': 'columns_and_descriptions', 'description': \"The question was what are the columns and their descriptions in the training set and the test set. The answer is that the columns and their descriptions can be found in the 'data_description.txt' file using the 'read_file' function. The columns and their descriptions in both the training set and the test set include information about the type of dwelling, zoning classification, lot size, road and alley access, property shape and flatness, utilities available, and lot configuration.\", 'parameters': {'type': 'object', 'properties': {}, 'required': []}}\n",
    "        ]\n",
    "\n",
    "        self.available_functions = {\n",
    "            \"read_file\": self.read_file,\n",
    "            \"write_file\": self.write_file,\n",
    "            \"web_search\": self.web_search,\n",
    "            \"think\": self.think,\n",
    "        }\n",
    "\n",
    "        # Currently not much utility, but if you needed to trace back to a function or fact it got wrong, this can help.\n",
    "        # TODO: honestly, not really sure what to do with this. I was thinking seeing the entire message history would be a good way to trace back, but we already have the original message prompt\n",
    "        self.function_history = [\n",
    "            \"given\",\n",
    "            \"given\",\n",
    "            \"given\",\n",
    "            \"given\",\n",
    "        ]\n",
    "\n",
    "        self.files = [\n",
    "            (\"train.csv\", \"the training set\"),\n",
    "            (\"test.csv\", \"the test set\"),\n",
    "            (\"data_description.txt\", \"full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\"),\n",
    "            (\"sample_submission.csv\", \"a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\"),\n",
    "            (\"data_fields.txt\", \"a brief version of what you'll find in the data description file.\"),\n",
    "        ]\n",
    "\n",
    "    def retrieve_tools(self, task, execution_feedback):\n",
    "        # For sake of simplicity, use recency for now (later relevancy and importance can be added)\n",
    "        func_name_description_list = [str((func[\"name\"], func[\"description\"])) + '\\n' for func in self.functions]\n",
    "        return func_name_description_list\n",
    "    \n",
    "    def retrieve_info_blocks(self, task, execution_feedback):\n",
    "        # retrieving file names and description\n",
    "        return [name + \" - \" + description for name, description in self.files]\n",
    "\n",
    "    # Helper function: be able to create a function with a dynamic name and return value\n",
    "    # def create_skill_function(self, function_name, return_value):\n",
    "    #     def dynamic_method(self):\n",
    "    #         return return_value\n",
    "    #     # Bind the function to the instance as a method\n",
    "    #     bound_method = types.MethodType(dynamic_method, self)\n",
    "    #     setattr(self, function_name, bound_method)\n",
    "    #     # Add the method to available functions\n",
    "    #     self.available_functions[function_name] = bound_method\n",
    "\n",
    "    # Core function: adding a new skill requires an original task, a validated answer, and a message history\n",
    "    def add_skill(self, task, validated_answer, methods_prompt):\n",
    "        # TODO: wait until the action agent generates a function because maybe you only need to write a description of the input function instead of task and validated answer.\n",
    "        # create_function_description_system_prompt = f'''You are a helpful assistant that writes a description of the given '''\n",
    "\n",
    "        print(\"Adding skills! \", task, validated_answer, methods_prompt)\n",
    "\n",
    "        create_skill_system_prompt = f'''You are a helpful assistant. Your goal is to write a short file name and a short description of the question and answer. \n",
    "        \n",
    "        You will receive this information:\n",
    "        Original task or question: ...\n",
    "        Answer: ...\n",
    "\n",
    "        Do not use any of these file names: {[name for name, _ in self.files]}\n",
    "\n",
    "        Your output should be in the following format if function requires arguments:\n",
    "        ```json\n",
    "        {{\n",
    "            \"name\": \"<file_name>\",\n",
    "            \"description\": \"<insert question and answer>\"\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        Good example output:\n",
    "        ```json\n",
    "        {{\n",
    "            \"name\": \"num_dogs_in_bens_family\",\n",
    "            \"description\": \"The question was how many dogs are in the family. Ben said that he has 2 dogs in his family.\"\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        Ensure the response can be parsed by Python \"json.loads\", e.g.: no trailing commas, no single quotes, etc. This is important.\n",
    "        '''\n",
    "\n",
    "        create_function_description_prompt = f'''\n",
    "        Original task or question: {task}\n",
    "        Answer: {validated_answer}\n",
    "        '''\n",
    "        res, messages = chat_openai(prompt=create_function_description_prompt, system_prompt=create_skill_system_prompt, verbose=True)\n",
    "        res\n",
    "\n",
    "        try:\n",
    "            # Load the function description\n",
    "            file_name_description = json.loads(res['content'])\n",
    "            print(\"file_name_description: \", file_name_description)\n",
    "\n",
    "            # Create the function as a method of skill_manager\n",
    "            self.write_file(file_name_description['name'], f\"Question: {task}\\nAnswer: {validated_answer}\\nReasoning and Methods: {methods_prompt}\")\n",
    "\n",
    "            # Add function to function description list\n",
    "            self.files.append((file_name_description['name'], file_name_description['description']))\n",
    "\n",
    "            print(\"COMPLETE!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            return\n",
    "\n",
    "        return\n",
    "\n",
    "    # Below are given functions or dummy functions\n",
    "    def read_file(self, file_name):\n",
    "        '''Get the text from the file'''\n",
    "        file_path = f'{root_file_directory}/{file_name}'\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read()[:self.READ_MAX_CHAR_SIZE]\n",
    "        return text\n",
    "    \n",
    "    def write_file(self, file_name, text):\n",
    "        '''Write the given text to the file.'''\n",
    "        file_path = f'{root_file_directory}/{file_name}'\n",
    "        with open(file_path, 'w') as file:  # 'w' is the mode for writing to a file\n",
    "            file.write(text)  # Write the entire text to the file\n",
    "        return text\n",
    "\n",
    "    def web_search(self, query):\n",
    "        # Temporarily just return search info from the user\n",
    "        return input(f\"Search for {query} on the web: \")\n",
    "        \n",
    "    def think(self, query):\n",
    "        return chat_openai(query + \" Think step by step.\", verbose=True)[0]['content']\n",
    "    \n",
    "    # Demo of how to add plain just fact / info skills that gets added as just natural language?\n",
    "    def content_in_data_txt(self):\n",
    "        return '''The data.txt file contains the following information: File descriptions\n",
    "train.csv - the training set\n",
    "test.csv - the test set\n",
    "data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\n",
    "sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\n",
    "data_fields.txt - a brief version of what you'll find in the data desc'ription file.'''\n",
    "\n",
    "    def num_children(self):\n",
    "        return '''There are 2 boys, and 8 girls'''\n",
    "    \n",
    "    # MANUALLY ADDED FUNCTIONS FOR TESTING\n",
    "    def columns_and_descriptions():\n",
    "        return '''The question was what are the columns and their descriptions in the training set and the test set. The answer is that the columns and their descriptions can be found in the 'data_description.txt' file using the 'read_file' function. The columns and their descriptions in both the training set and the test set include information about the type of dwelling, zoning classification, lot size, road and alley access, property shape and flatness, utilities available, and lot configuration.'''\n",
    "    \n",
    "skill_manager = SkillManager()\n",
    "print(\"Available functions: \\n\", skill_manager.available_functions, \"\\n\\nFunctions\", skill_manager.functions, \"\\n\\nAvailable files: \\n\", skill_manager.retrieve_info_blocks(\"\", \"\"))\n",
    "# Unit test to ensure that the skill manager's basic skills work\n",
    "skill_manager.write_file(\"hello_world.txt\", \"hello_world\")\n",
    "assert(os.path.isfile(f'{root_file_directory}/hello_world.txt'))\n",
    "read_file_result = skill_manager.read_file(\"hello_world.txt\")\n",
    "assert(read_file_result == \"hello_world\")\n",
    "web_search_result = skill_manager.web_search(\"Do penguins fly?\")\n",
    "assert(len(web_search_result) > 0 and type(web_search_result) == str)\n",
    "# think_result = skill_manager.think(\"Do penguins fly?\") # Commenting out just for now since it costs to test\n",
    "# assert(len(think_result) > 0 and type(think_result) == str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionAgent():\n",
    "    # TODO: does there need to be an action agent generating the steps? Or does there need to be a separate execution agent running the prompt? Or can the action agent be the execution agent?\n",
    "    # TODO: can a critic agent really check if the output is correct? Or can they only check if that aligns with expectation? Otherwise, the critic will have to check the line of content values to make sure the reasoning is sound, which is still doable, but the extent that another critic can check is limited. I guess it's just to make sure the reasoning is sound.\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def generate_function_callable_prompt(self, task,\n",
    "                methods_prompt,\n",
    "                execution_feedback,\n",
    "                execution_errors,\n",
    "                critique,\n",
    "                skills,\n",
    "                skill_manager):\n",
    "        generate_function_callable_system_prompt = f'''You are a helpful assistant and a first-rate problem solver. Given a task or question, your goal is to list out the steps to solve that task or question given your skills and reasoning. Ultimately, your output should be able to be followed by a human limited by the skills and knowledge given, and another human should be able to check that human's output to see if it's correct and reasonable. Note that the functions asked for may sometimes already be called and the information from the function that you need is already in the prompt, so read carefully. Note that you DO NOT have access to run any code, you can only read, think, and write about the existing skills and knowledge.\n",
    "        \n",
    "        You will be given this information:\n",
    "        Task or question: ...\n",
    "        Skills: You only have these skills to help you write the steps to achieve this task or answer this question.\n",
    "        Knowledge: You only have these information blocks as files that you can read to get more information about the details of the information block's answer and the reasoning and methods used to arrive at the answer.\n",
    "        Current state steps: ...\n",
    "        Current state output after executing steps: ...\n",
    "        Execution errors: ...\n",
    "        Critique: ...\n",
    "        \n",
    "        Please output your list of steps that can be followed and answer the question and address any critiques.'''\n",
    "\n",
    "        user_prompt = f'''Task or question: {task}\n",
    "        Skills: {skills}\n",
    "        Knowledge: {skill_manager.retrieve_info_blocks()}\n",
    "        Current state solution: {methods_prompt}\n",
    "        Current state output after executing steps: {execution_feedback}\n",
    "        Execution errors: {execution_errors}\n",
    "        Critique: {critique}'''\n",
    "\n",
    "        agent_methods_feedback, agent_methods_errors = self.function_call(generate_function_callable_system_prompt, user_prompt, skill_manager)\n",
    "\n",
    "        # TODO: Add error handling for if the agent_methods_feedback is empty and agent_methods_errors exists\n",
    "        print(\"agent_methods_feedback\", agent_methods_feedback, \"agent_methods_errors\", agent_methods_errors)\n",
    "\n",
    "        return f'Task or question: {task} \\nInstructions: ' + agent_methods_feedback['content']\n",
    "    \n",
    "    def function_call(self, system_prompt, methods_prompt, skill_manager):\n",
    "        print()\n",
    "        try:\n",
    "            response_message, messages = chat_openai(system_prompt=system_prompt, prompt=methods_prompt, functions=skill_manager.functions, available_functions=skill_manager.available_functions,verbose=True)\n",
    "        except Exception as e:\n",
    "            return \"\", e\n",
    "        return response_message, None\n",
    "    \n",
    "action_agent = ActionAgent()\n",
    "methods_prompt = None\n",
    "execution_feedback = None\n",
    "execution_errors = None\n",
    "critique = None\n",
    "success = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecutionAgent():\n",
    "    # Ultimately the answer will go into Description or be \"returned\" with the description being condensed into a tldr and the methods_prompt will be added to history\n",
    "\n",
    "    def function_call(self, methods_prompt, skill_manager):\n",
    "        system_prompt = f'''You are a helpful assistant. Your goal is to execute the given instructions and output the complete answer to the question. If the instructions don't seem reasonable or you cannot get to the complete answer, then you should give feedback on why you couldn't do it and what you tried. \n",
    "\n",
    "        You will be given this information:\n",
    "        Instructions: ...\n",
    "'''\n",
    "        \n",
    "        try:\n",
    "            response_message, messages = chat_openai(system_prompt=system_prompt, prompt=methods_prompt, functions=skill_manager.functions, available_functions=skill_manager.available_functions,verbose=True)\n",
    "            conclusion = response_message['content'] \n",
    "\n",
    "            # # Assuming response_message['content'] is a string that contains 'Conclusion:'\n",
    "            # match = re.search(r'Conclusion:(.*)', response_message['content'], re.DOTALL)\n",
    "            # if match:\n",
    "            #     conclusion = match.group(1).strip()\n",
    "            # else:\n",
    "            #     conclusion = response_message['content']  # or some default value, in case \"Conclusion:\" isn't found\n",
    "        except Exception as e:\n",
    "            return \"\", e\n",
    "        return conclusion, None\n",
    "execution_agent = ExecutionAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticAgent():\n",
    "    # TODO: Perhaps include the skills to the critic so the critic knows the facts to check if this makes sense or not\n",
    "\n",
    "    def check_task_success(self, task, methods_prompt, execution_feedback, skills, skill_manager):\n",
    "        system_prompt = '''You are an assistant that assesses my progress of research and provides useful guidance. \n",
    "        \n",
    "        You are required to evaluate if I have provided a complete and actual answer to the question. Providing more information and exceeding the task requirements is also considered a success while failing to meet them or not actually answering the question requires you to provide critique to help me improve.\n",
    "\n",
    "        I will give you the following information:\n",
    "        Skills & knowledge: My skills and pieces of information and knowledge I have. \n",
    "        Files: My files.\n",
    "        Task or question: The question I need to answer.\n",
    "        Answer: My current answer.\n",
    "        Approach: My reasoning of how I got to my answer.\n",
    "\n",
    "        You should only respond in JSON format as described below:\n",
    "        {\n",
    "            \"reasoning\": \"reasoning\",\n",
    "            \"success\": boolean,\n",
    "            \"critique\": \"critique\",\n",
    "        }\n",
    "        Ensure the response can be parsed by Python \"json.loads\", e.g.: no trailing commas, no single quotes, etc.\n",
    "\n",
    "        Here are some examples:\n",
    "        INPUT:\n",
    "        Task or question: What is the distribution of the sale prices in the dataset?\n",
    "        Answer: To determine the distribution of the sale prices in the dataset, we can follow these steps:\\n\\n1. Read the dataset file \"train.csv\" using the `read_file` function.\\n2. Extract the column containing the sale prices from the dataset.\\n3. Calculate the frequency of each unique sale price in the dataset.\\n4. Sort the unique sale prices in ascending order.\\n5. Create a histogram or bar chart to visualize the distribution of the sale prices.\\n6. Optionally, you can also calculate summary statistics such as mean, median, and standard deviation of the sale prices.\\n\\nLet\\'s start by reading the dataset file \"train.csv\".\n",
    "        Approach: Task or question: What is the distribution of the sale prices in the dataset? \\nInstructions: To determine the distribution of the sale prices in the dataset, you can follow these steps:\\n\\n1. Read the dataset file \"train.csv\" using the `read_file` function.\\n2. Extract the column containing the sale prices from the dataset.\\n3. Calculate the frequency of each unique sale price in the dataset.\\n4. Sort the unique sale prices in ascending order.\\n5. Create a histogram or bar chart to visualize the distribution of the sale prices.\\n6. Optionally, you can also calculate summary statistics such as mean, median, and standard deviation of the sale prices.\\n\\nPlease note that the specific implementation details may vary depending on the programming language and libraries you are using.\n",
    "\n",
    "        RESPONSE:\n",
    "        {\n",
    "            \"reasoning\": The reasoning to get to the answer makes sense, but I don't see an answer for what the actual distribution of the sale price is.,\n",
    "            \"success\": False,\n",
    "            \"critique\": The answer only tells us how to get the distribution is, but does not tell us what the actual distribution.\n",
    "        }\n",
    "        '''\n",
    "\n",
    "        user_prompt = f'''Skills & knowledge: {skills}\n",
    "        Files: {skill_manager.files}\n",
    "        Task or question: {task}\n",
    "        Answer: {execution_feedback}\n",
    "        Approach: {methods_prompt}'''\n",
    "\n",
    "        response_message, messages = chat_openai(system_prompt=system_prompt, prompt=user_prompt, verbose=True)\n",
    "\n",
    "        response_json = json.loads(response_message['content'])\n",
    "        success = response_json['success']\n",
    "        reasoning = response_json['reasoning']\n",
    "        critique = response_json['critique']\n",
    "\n",
    "        # lines = response_message['content'].split(\"\\n\")\n",
    "        # for line in lines:\n",
    "        #     # Strip whitespace for accurate matching\n",
    "        #     line = line.strip()\n",
    "            \n",
    "        #     # Check if the line starts with the known titles and parse accordingly\n",
    "        #     if line.startswith('Reasoning:'):\n",
    "        #         critique = line[len('Reasoning:'):].strip()\n",
    "        #     elif line.startswith('Task is reasonably answered:'):\n",
    "        #         success = line[len('Task is reasonably answered:'):].strip().lower()\n",
    "\n",
    "        print(\"System prompt: \", system_prompt, \"\\nUser prompt: \", user_prompt, \"\\nResponse: \", response_message['content'])\n",
    "        return success, critique\n",
    "critic_agent = CriticAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate only once! \n",
    "skill_manager = SkillManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START HERE FOR NEXT ITERATIONS: Save the current iteration's state after this cycle in case we need to revert\n",
    "skill_manager_copy = copy.deepcopy(skill_manager)\n",
    "curriculum_agent_copy = copy.deepcopy(curriculum_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVERT BY STARTING HERE, uncomment the below and run\n",
    "# skill_manager = copy.deepcopy(skill_manager_copy)\n",
    "# curriculum_agent = copy.deepcopy(curriculum_agent_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curriculum_agent.completed_tasks ['What are the columns and their descriptions in the training set and the test set?'] curriculum_agent.failed_tasks []\n"
     ]
    }
   ],
   "source": [
    "print(\"curriculum_agent.completed_tasks\", curriculum_agent.completed_tasks, \"curriculum_agent.failed_tasks\", curriculum_agent.failed_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curriculum_agent.completed_tasks ['What are the columns and their descriptions in the training set and the test set?']\n",
      "System prompt for generating curriculum: \n",
      " You are a helpful assistant that asks questions to help me decide the next immediate question to answer on the computer. My ultimate goal is to discover as many useful pieces of information as possible, answer as many questions as possible, and become the best researcher in the world.\n",
      "\n",
      "        Goal: \n",
      "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
      "\n",
      "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
      "\n",
      "Goal\n",
      "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. \n",
      "\n",
      "Metric\n",
      "Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n",
      "\n",
      "Submission File Format\n",
      "The file should contain a header and have the following format:\n",
      "\n",
      "Id,SalePrice\n",
      "1461,169000.1\n",
      "1462,187724.1233\n",
      "1463,175221\n",
      "etc.\n",
      "\n",
      "\n",
      "        I will give you the following information:\n",
      "        Memory (oldest to newest): ...\n",
      "        Recent links: ...\n",
      "        Root folder inventory: ...\n",
      "        Saved notes: ...\n",
      "        Completed tasks so far: ...\n",
      "        Failed tasks that are too hard: ...\n",
      "\n",
      "        1) You should act as a mentor and guide me to the next question based on my current learning progress.\n",
      "        2) Please be very specific about what question I need to answer.\n",
      "        3) The next question should follow a clear format, such as \"What do other papers say about [topic]\", \"What are the problems with [approach]\", \"How can I solve this [problem]\", \"Can results from [topic 1] be applied to [topic 2]?\", \"What are the similarities between [topic 1] for success and [topic 2]\" , \"What's significant about this paper: [paper]?\", \"What does [topic] mean?\", etc. It should be a single question to collect useful information on. Do not propose multiple questions at the same time. Do not mention anything else. \n",
      "        4) The next question should not be too hard since the internet and I may not contain the full answer in a single article or have learned enough information to complete it yet. \n",
      "        5) The next question should be novel and interesting based on my current learning progress. I should look for rare and potentially useful pieces of information, upgrade my saved notes using better information, and discover new things. I should not be doing the same thing over and over again.\n",
      "        6) I may sometimes need to repeat some questions or variations of the question if I need to collect more information to answer more difficult question. Only repeat questions if necessary. \n",
      "        7) I want to explore the world and discover new things. I don’t want to stay in my current state for too long. \n",
      "        8) Questions that require information beyond another person's ability to theoretically verify and reason if completed or correct should be avoided. For instance, \"what else is there on the website?\" and \"what images and tables are on the website\" are not ideal since they require visual confirmation from the screen. All the testing, coding, and asking other people questions should be avoided. Do not propose a question with these keywords. You should only respond in the format as described below:\n",
      "        \n",
      "        RESPONSE FORMAT: \n",
      "        Reasoning: Based on the information I listed above, do reasoning about what the next question should be. \n",
      "        Question: The next question. \n",
      "        \n",
      "        Here’s an example response: \n",
      "        Reasoning: We know the we have a sword and we know there's fire, and fire lights things on fire. Therefore, we could try to make a firesword.\n",
      "        Question: Could we make a firesword?\n",
      " \n",
      " User prompt:  Memory: []\n",
      "\n",
      "Root folder inventory: train.csv - the training set\n",
      "test.csv - the test set\n",
      "data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\n",
      "sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\n",
      "data_fields.txt - a brief version of what you'll find in the data description file.\n",
      "\n",
      "\n",
      "Saved notes: \n",
      "\n",
      "Completed tasks so far: ['What are the columns and their descriptions in the training set and the test set?']\n",
      "\n",
      "Failed tasks that are too hard: []\n",
      "\n",
      "\n",
      "Response:  Reasoning: Since we have already explored the columns and their descriptions in the training set and the test set, the next logical step would be to understand the target variable, which is the \"SalePrice\". We should explore the distribution and characteristics of the sale prices in the dataset.\n",
      "\n",
      "Question: What is the distribution of the sale prices in the dataset?\n",
      "next_question What is the distribution of the sale prices in the dataset?\n"
     ]
    }
   ],
   "source": [
    "print(\"curriculum_agent.completed_tasks\", curriculum_agent.completed_tasks)\n",
    "next_question = curriculum_agent.propose_next_question(skills=skill_manager.retrieve_skills(task=\"\", execution_feedback=\"\"), exploration_progress=[])\n",
    "print(\"next_question\", next_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current skills\n",
      " [\"('read_file', 'Get the text from the file')\\n\", \"('write_file', 'Write text to a file')\\n\", '(\\'web_search\\', \"Given a prompt, I\\'ll return back my web search information about it\")\\n', '(\\'think\\', \"Given a prompt, I\\'ll return back my thoughts on it.\")\\n', \"('num_children', 'This paper talks about how many girls and boys are in this family')\\n\", \"('columns_and_descriptions', 'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\\\n\\\\nTraining Set:\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\n4. LotArea: Lot size in square feet.\\\\n5. Street: Type of road access to property.\\\\n6. Alley: Type of alley access to property.\\\\n7. LotShape: General shape of property.\\\\n8. LandContour: Flatness of the property.\\\\n9. Utilities: Type of utilities available.\\\\n10. LotConfig: Lot configuration.\\\\n11. LandSlope: Slope of property.\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\n\\\\nTest Set:\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\n4. LotArea: Lot size in square feet.\\\\n5. Street: Type of road access to property.\\\\n6. Alley: Type of alley access to property.\\\\n7. LotShape: General shape of property.\\\\n8. LandContour: Flatness of the property.\\\\n9. Utilities: Type of utilities available.\\\\n10. LotConfig: Lot configuration.\\\\n11. LandSlope: Slope of property.\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\n\\\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.')\\n\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCurrent skills\\n\", skill_manager.retrieve_skills(task=\"\", execution_feedback=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'read_file', 'description': 'Get the text from the file', 'parameters': {'type': 'object', 'properties': {'file_name': {'type': 'string', 'description': 'the complete file name and extension, e.g. abc.txt'}}, 'required': ['file_name']}}, {'name': 'write_file', 'description': 'Write text to a file', 'parameters': {'type': 'object', 'properties': {'file_name': {'type': 'string', 'description': 'the complete file name and extension, e.g. abc.txt'}, 'text': {'type': 'string', 'description': 'the text to write to the file'}}, 'required': ['file_name', 'text']}}, {'name': 'web_search', 'description': \"Given a prompt, I'll return back my web search information about it\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Tell me what to search about'}}, 'required': ['query']}}, {'name': 'think', 'description': \"Given a prompt, I'll return back my thoughts on it.\", 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Tell me what to think about'}}, 'required': ['query']}}, {'name': 'num_children', 'description': 'This paper talks about how many girls and boys are in this family', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}, {'name': 'columns_and_descriptions', 'description': 'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\n\\nTraining Set:\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\n2. MSZoning: Identifies the general zoning classification of the sale.\\n3. LotFrontage: Linear feet of street connected to property.\\n4. LotArea: Lot size in square feet.\\n5. Street: Type of road access to property.\\n6. Alley: Type of alley access to property.\\n7. LotShape: General shape of property.\\n8. LandContour: Flatness of the property.\\n9. Utilities: Type of utilities available.\\n10. LotConfig: Lot configuration.\\n11. LandSlope: Slope of property.\\n12. Neighborhood: Physical locations within Ames city limits.\\n\\nTest Set:\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\n2. MSZoning: Identifies the general zoning classification of the sale.\\n3. LotFrontage: Linear feet of street connected to property.\\n4. LotArea: Lot size in square feet.\\n5. Street: Type of road access to property.\\n6. Alley: Type of alley access to property.\\n7. LotShape: General shape of property.\\n8. LandContour: Flatness of the property.\\n9. Utilities: Type of utilities available.\\n10. LotConfig: Lot configuration.\\n11. LandSlope: Slope of property.\\n12. Neighborhood: Physical locations within Ames city limits.\\n\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}]\n",
      "{'read_file': <bound method SkillManager.read_file of <__main__.SkillManager object at 0x0000014ED0583350>>, 'write_file': <bound method SkillManager.write_file of <__main__.SkillManager object at 0x0000014ED0583350>>, 'web_search': <bound method SkillManager.web_search of <__main__.SkillManager object at 0x0000014ED0583350>>, 'think': <bound method SkillManager.think of <__main__.SkillManager object at 0x0000014ED0583350>>, 'num_children': <bound method SkillManager.num_children of <__main__.SkillManager object at 0x0000014ED0583350>>, 'columns_and_descriptions': <bound method SkillManager.create_skill_function.<locals>.dynamic_method of <__main__.SkillManager object at 0x0000014ED0583350>>}\n"
     ]
    }
   ],
   "source": [
    "print(skill_manager.functions)\n",
    "print(skill_manager.available_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_question What is the distribution of the sale prices in the dataset?\n"
     ]
    }
   ],
   "source": [
    "# Attempting to build 1 cycle with all agents\n",
    "# next_question = \"Search up how many penguins there are in Kevin Huang's house. We don't need an exact or true number.\"\n",
    "# next_question = \"What is the total number of penguins and children that we know about from our functions?\" # hardcoded for now\n",
    "num_rounds = 2\n",
    "num_tasks = 1\n",
    "print(\"next_question\", next_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Round 0 Task: \n",
      " What is the distribution of the sale prices in the dataset?\n",
      "\n",
      "Skill manager output:\n",
      " [\"('read_file', 'Get the text from the file')\\n\", \"('write_file', 'Write text to a file')\\n\", '(\\'web_search\\', \"Given a prompt, I\\'ll return back my web search information about it\")\\n', '(\\'think\\', \"Given a prompt, I\\'ll return back my thoughts on it.\")\\n', \"('num_children', 'This paper talks about how many girls and boys are in this family')\\n\", \"('columns_and_descriptions', 'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\\\n\\\\nTraining Set:\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\n4. LotArea: Lot size in square feet.\\\\n5. Street: Type of road access to property.\\\\n6. Alley: Type of alley access to property.\\\\n7. LotShape: General shape of property.\\\\n8. LandContour: Flatness of the property.\\\\n9. Utilities: Type of utilities available.\\\\n10. LotConfig: Lot configuration.\\\\n11. LandSlope: Slope of property.\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\n\\\\nTest Set:\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\n4. LotArea: Lot size in square feet.\\\\n5. Street: Type of road access to property.\\\\n6. Alley: Type of alley access to property.\\\\n7. LotShape: General shape of property.\\\\n8. LandContour: Flatness of the property.\\\\n9. Utilities: Type of utilities available.\\\\n10. LotConfig: Lot configuration.\\\\n11. LandSlope: Slope of property.\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\n\\\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.')\\n\"]\n",
      "\n",
      "Starting action agent\n",
      "\n",
      "Prompt messages:  [{'role': 'system', 'content': \"You are a helpful assistant and a first-rate problem solver. Given a task or question, your goal is to list out the steps to solve that task or question given your skills and reasoning. Ultimately, your output should be able to be followed by a human limited by the skills and knowledge given, and another human should be able to check that human's output to see if it's correct and reasonable. Note that the functions asked for may sometimes already be called and the information from the function that you need is already in the prompt, so read carefully. Note that you DO NOT have access to run any code, you can only read, think, and write about the existing skills and knowledge.\\n        \\n        You will be given this information:\\n        Task or question: ...\\n        Skills & knowledge: You only have these skills and pieces of knowledge in the format of (function name which represents a concept / ability, a description of that concept and ability that you can invoke) to help you write the steps to achieve this task or answer this question. You can call a function (sometimes with or without arguments) to just get more information too.\\n        Files: ... \\n        Current state steps: ...\\n        Current state output after executing steps: ...\\n        Execution errors: ...\\n        Critique: ...\\n        \\n        Please output your list of steps that can be followed and answer the question and address any critiques.\"}, {'role': 'user', 'content': 'Task or question: What is the distribution of the sale prices in the dataset?\\n        Skills & knowledge: [\"(\\'read_file\\', \\'Get the text from the file\\')\\\\n\", \"(\\'write_file\\', \\'Write text to a file\\')\\\\n\", \\'(\\\\\\'web_search\\\\\\', \"Given a prompt, I\\\\\\'ll return back my web search information about it\")\\\\n\\', \\'(\\\\\\'think\\\\\\', \"Given a prompt, I\\\\\\'ll return back my thoughts on it.\")\\\\n\\', \"(\\'num_children\\', \\'This paper talks about how many girls and boys are in this family\\')\\\\n\", \"(\\'columns_and_descriptions\\', \\'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\\\\\\\n\\\\\\\\nTraining Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nTest Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.\\')\\\\n\"]\\n        Files: [\\'train.csv - the training set\\', \\'test.csv - the test set\\', \\'data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\\', \\'sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\\', \"data_fields.txt - a brief version of what you\\'ll find in the data description file.\"]\\n        Current state solution: None\\n        Current state output after executing steps: None\\n        Execution errors: None\\n        Critique: None'}]\n",
      "   *** OpenAI API invalid request. Check the documentation for the specific API method you are calling and make sure you are sending valid and complete parameters. Waiting 10 seconds and trying again. ***\n",
      "Prompt messages:  [{'role': 'system', 'content': \"You are a helpful assistant and a first-rate problem solver. Given a task or question, your goal is to list out the steps to solve that task or question given your skills and reasoning. Ultimately, your output should be able to be followed by a human limited by the skills and knowledge given, and another human should be able to check that human's output to see if it's correct and reasonable. Note that the functions asked for may sometimes already be called and the information from the function that you need is already in the prompt, so read carefully. Note that you DO NOT have access to run any code, you can only read, think, and write about the existing skills and knowledge.\\n        \\n        You will be given this information:\\n        Task or question: ...\\n        Skills & knowledge: You only have these skills and pieces of knowledge in the format of (function name which represents a concept / ability, a description of that concept and ability that you can invoke) to help you write the steps to achieve this task or answer this question. You can call a function (sometimes with or without arguments) to just get more information too.\\n        Files: ... \\n        Current state steps: ...\\n        Current state output after executing steps: ...\\n        Execution errors: ...\\n        Critique: ...\\n        \\n        Please output your list of steps that can be followed and answer the question and address any critiques.\"}, {'role': 'user', 'content': 'Task or question: What is the distribution of the sale prices in the dataset?\\n        Skills & knowledge: [\"(\\'read_file\\', \\'Get the text from the file\\')\\\\n\", \"(\\'write_file\\', \\'Write text to a file\\')\\\\n\", \\'(\\\\\\'web_search\\\\\\', \"Given a prompt, I\\\\\\'ll return back my web search information about it\")\\\\n\\', \\'(\\\\\\'think\\\\\\', \"Given a prompt, I\\\\\\'ll return back my thoughts on it.\")\\\\n\\', \"(\\'num_children\\', \\'This paper talks about how many girls and boys are in this family\\')\\\\n\", \"(\\'columns_and_descriptions\\', \\'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\\\\\\\n\\\\\\\\nTraining Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nTest Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.\\')\\\\n\"]\\n        Files: [\\'train.csv - the training set\\', \\'test.csv - the test set\\', \\'data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\\', \\'sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\\', \"data_fields.txt - a brief version of what you\\'ll find in the data description file.\"]\\n        Current state solution: None\\n        Current state output after executing steps: None\\n        Execution errors: None\\n        Critique: None'}]\n",
      "   *** OpenAI API invalid request. Check the documentation for the specific API method you are calling and make sure you are sending valid and complete parameters. Waiting 10 seconds and trying again. ***\n",
      "Prompt messages:  [{'role': 'system', 'content': \"You are a helpful assistant and a first-rate problem solver. Given a task or question, your goal is to list out the steps to solve that task or question given your skills and reasoning. Ultimately, your output should be able to be followed by a human limited by the skills and knowledge given, and another human should be able to check that human's output to see if it's correct and reasonable. Note that the functions asked for may sometimes already be called and the information from the function that you need is already in the prompt, so read carefully. Note that you DO NOT have access to run any code, you can only read, think, and write about the existing skills and knowledge.\\n        \\n        You will be given this information:\\n        Task or question: ...\\n        Skills & knowledge: You only have these skills and pieces of knowledge in the format of (function name which represents a concept / ability, a description of that concept and ability that you can invoke) to help you write the steps to achieve this task or answer this question. You can call a function (sometimes with or without arguments) to just get more information too.\\n        Files: ... \\n        Current state steps: ...\\n        Current state output after executing steps: ...\\n        Execution errors: ...\\n        Critique: ...\\n        \\n        Please output your list of steps that can be followed and answer the question and address any critiques.\"}, {'role': 'user', 'content': 'Task or question: What is the distribution of the sale prices in the dataset?\\n        Skills & knowledge: [\"(\\'read_file\\', \\'Get the text from the file\\')\\\\n\", \"(\\'write_file\\', \\'Write text to a file\\')\\\\n\", \\'(\\\\\\'web_search\\\\\\', \"Given a prompt, I\\\\\\'ll return back my web search information about it\")\\\\n\\', \\'(\\\\\\'think\\\\\\', \"Given a prompt, I\\\\\\'ll return back my thoughts on it.\")\\\\n\\', \"(\\'num_children\\', \\'This paper talks about how many girls and boys are in this family\\')\\\\n\", \"(\\'columns_and_descriptions\\', \\'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\\\\\\\n\\\\\\\\nTraining Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nTest Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.\\')\\\\n\"]\\n        Files: [\\'train.csv - the training set\\', \\'test.csv - the test set\\', \\'data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\\', \\'sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\\', \"data_fields.txt - a brief version of what you\\'ll find in the data description file.\"]\\n        Current state solution: None\\n        Current state output after executing steps: None\\n        Execution errors: None\\n        Critique: None'}]\n",
      "   *** OpenAI API invalid request. Check the documentation for the specific API method you are calling and make sure you are sending valid and complete parameters. Waiting 10 seconds and trying again. ***\n",
      "Retry happened 3 times! Kicking in to save you tokens.\n",
      "agent_methods_feedback  agent_methods_errors cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\autoscious-carbon-capture\\eureka_exp\\eureka-kevin-questions.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStarting action agent\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m action_agent \u001b[39m=\u001b[39m ActionAgent()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m methods_prompt \u001b[39m=\u001b[39m action_agent\u001b[39m.\u001b[39;49mgenerate_function_callable_prompt(next_question, methods_prompt, execution_feedback, execution_errors, critique, skills, skill_manager)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAction agent output:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, methods_prompt)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStarting execution agent\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\autoscious-carbon-capture\\eureka_exp\\eureka-kevin-questions.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X33sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# TODO: Add error handling for if the agent_methods_feedback is empty and agent_methods_errors exists\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X33sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39magent_methods_feedback\u001b[39m\u001b[39m\"\u001b[39m, agent_methods_feedback, \u001b[39m\"\u001b[39m\u001b[39magent_methods_errors\u001b[39m\u001b[39m\"\u001b[39m, agent_methods_errors)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X33sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTask or question: \u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m agent_methods_feedback[\u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "for task_idx in range(num_tasks):\n",
    "    methods_prompt = None\n",
    "    execution_feedback = None\n",
    "    execution_errors = None\n",
    "    critique = None\n",
    "    success = False\n",
    "    for i in range (num_rounds):\n",
    "        print(f\"\\nRound {i} Task: \\n\", next_question)\n",
    "        \n",
    "        skills = skill_manager.retrieve_skills(next_question, execution_feedback=None)\n",
    "        print(\"\\nSkill manager output:\\n\", skills)\n",
    "\n",
    "        print(\"\\nStarting action agent\")\n",
    "        action_agent = ActionAgent()\n",
    "        methods_prompt = action_agent.generate_function_callable_prompt(next_question, methods_prompt, execution_feedback, execution_errors, critique, skills, skill_manager)\n",
    "        print(\"\\nAction agent output:\\n\", methods_prompt)\n",
    "\n",
    "        print(\"\\nStarting execution agent\")\n",
    "        execution_agent = ExecutionAgent()\n",
    "        execution_feedback, execution_errors = execution_agent.function_call(methods_prompt, skill_manager)\n",
    "        print(\"\\nExecution agent output: \", execution_feedback, \"\\nExecution errors: \", execution_errors)\n",
    "\n",
    "        if execution_errors:\n",
    "            continue\n",
    "\n",
    "        print(\"\\nStarting critic agent\")\n",
    "        critic_agent = CriticAgent()\n",
    "        success, critique = critic_agent.check_task_success(next_question, methods_prompt, execution_feedback, skills, skill_manager)\n",
    "        print(\"Critic agent output\", \"\\nSuccess: \", success, \"\\nCritique: \", critique)\n",
    "\n",
    "        if success:\n",
    "            break\n",
    "    if success:\n",
    "        print(\"\\nBefore adding skill\\n\", skill_manager.retrieve_skills(\"\", execution_feedback=None))\n",
    "        skill_manager.add_skill(next_question, execution_feedback, methods_prompt)\n",
    "        print(\"\\nAfter adding skill\\n\", skill_manager.retrieve_skills(\"\", execution_feedback=None))\n",
    "        curriculum_agent.add_completed_task(next_question)\n",
    "    else:\n",
    "        curriculum_agent.add_failed_task(next_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt messages:  [{'role': 'system', 'content': \"You are a helpful assistant and a first-rate problem solver. Given a task or question, your goal is to list out the steps to solve that task or question given your skills and reasoning. Ultimately, your output should be able to be followed by a human limited by the skills and knowledge given, and another human should be able to check that human's output to see if it's correct and reasonable. Note that the functions asked for may sometimes already be called and the information from the function that you need is already in the prompt, so read carefully. Note that you DO NOT have access to run any code, you can only read, think, and write about the existing skills and knowledge.\\n        \\n        You will be given this information:\\n        Task or question: ...\\n        Skills & knowledge: You only have these skills and pieces of knowledge in the format of (function name which represents a concept / ability, a description of that concept and ability that you can invoke) to help you write the steps to achieve this task or answer this question. You can call a function (sometimes with or without arguments) to just get more information too.\\n        Files: ... \\n        Current state steps: ...\\n        Current state output after executing steps: ...\\n        Execution errors: ...\\n        Critique: ...\\n        \\n        Please output your list of steps that can be followed and answer the question and address any critiques.\"}, {'role': 'user', 'content': 'Task or question: What is the distribution of the sale prices in the dataset?\\n        Skills & knowledge: [\"(\\'read_file\\', \\'Get the text from the file\\')\\\\n\", \"(\\'write_file\\', \\'Write text to a file\\')\\\\n\", \\'(\\\\\\'web_search\\\\\\', \"Given a prompt, I\\\\\\'ll return back my web search information about it\")\\\\n\\', \\'(\\\\\\'think\\\\\\', \"Given a prompt, I\\\\\\'ll return back my thoughts on it.\")\\\\n\\', \"(\\'num_children\\', \\'This paper talks about how many girls and boys are in this family\\')\\\\n\", \"(\\'columns_and_descriptions\\', \\'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\\\\\\\n\\\\\\\\nTraining Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nTest Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.\\')\\\\n\"]\\n        Files: [\\'train.csv - the training set\\', \\'test.csv - the test set\\', \\'data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\\', \\'sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\\', \"data_fields.txt - a brief version of what you\\'ll find in the data description file.\"]\\n        Current state solution: None\\n        Current state output after executing steps: None\\n        Execution errors: None\\n        Critique: None'}]\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\n\\nTraining Set:\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\n2. MSZoning: Identifies the general zoning classification of the sale.\\n3. LotFrontage: Linear feet of street connected to property.\\n4. LotArea: Lot size in square feet.\\n5. Street: Type of road access to property.\\n6. Alley: Type of alley access to property.\\n7. LotShape: General shape of property.\\n8. LandContour: Flatness of the property.\\n9. Utilities: Type of utilities available.\\n10. LotConfig: Lot configuration.\\n11. LandSlope: Slope of property.\\n12. Neighborhood: Physical locations within Ames city limits.\\n\\nTest Set:\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\n2. MSZoning: Identifies the general zoning classification of the sale.\\n3. LotFrontage: Linear feet of street connected to property.\\n4. LotArea: Lot size in square feet.\\n5. Street: Type of road access to property.\\n6. Alley: Type of alley access to property.\\n7. LotShape: General shape of property.\\n8. LandContour: Flatness of the property.\\n9. Utilities: Type of utilities available.\\n10. LotConfig: Lot configuration.\\n11. LandSlope: Slope of property.\\n12. Neighborhood: Physical locations within Ames city limits.\\n\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.' is too long - 'functions.5.description'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\autoscious-carbon-capture\\eureka_exp\\eureka-kevin-questions.ipynb Cell 19\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# create the chat completion\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPrompt messages: \u001b[39m\u001b[39m\"\u001b[39m, messages)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     functions\u001b[39m=\u001b[39;49mskill_manager\u001b[39m.\u001b[39;49mfunctions,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     function_call\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCompletion info: \u001b[39m\u001b[39m\"\u001b[39m, completion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kevihuang/OneDrive%20-%20Microsoft/Desktop/projects/autoscious-carbon-capture/eureka_exp/eureka-kevin-questions.ipynb#X53sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m response_message \u001b[39m=\u001b[39m completion[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\autoscious-carbon-capture\\eureka_exp\\venv2\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\autoscious-carbon-capture\\eureka_exp\\venv2\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\autoscious-carbon-capture\\eureka_exp\\venv2\\Lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\autoscious-carbon-capture\\eureka_exp\\venv2\\Lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kevihuang\\OneDrive - Microsoft\\Desktop\\projects\\autoscious-carbon-capture\\eureka_exp\\venv2\\Lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: 'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\n\\nTraining Set:\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\n2. MSZoning: Identifies the general zoning classification of the sale.\\n3. LotFrontage: Linear feet of street connected to property.\\n4. LotArea: Lot size in square feet.\\n5. Street: Type of road access to property.\\n6. Alley: Type of alley access to property.\\n7. LotShape: General shape of property.\\n8. LandContour: Flatness of the property.\\n9. Utilities: Type of utilities available.\\n10. LotConfig: Lot configuration.\\n11. LandSlope: Slope of property.\\n12. Neighborhood: Physical locations within Ames city limits.\\n\\nTest Set:\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\n2. MSZoning: Identifies the general zoning classification of the sale.\\n3. LotFrontage: Linear feet of street connected to property.\\n4. LotArea: Lot size in square feet.\\n5. Street: Type of road access to property.\\n6. Alley: Type of alley access to property.\\n7. LotShape: General shape of property.\\n8. LandContour: Flatness of the property.\\n9. Utilities: Type of utilities available.\\n10. LotConfig: Lot configuration.\\n11. LandSlope: Slope of property.\\n12. Neighborhood: Physical locations within Ames city limits.\\n\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.' is too long - 'functions.5.description'"
     ]
    }
   ],
   "source": [
    "# Debug because I kept on getting an invalid request error:\n",
    "messages = [{'role': 'system', 'content': \"You are a helpful assistant and a first-rate problem solver. Given a task or question, your goal is to list out the steps to solve that task or question given your skills and reasoning. Ultimately, your output should be able to be followed by a human limited by the skills and knowledge given, and another human should be able to check that human's output to see if it's correct and reasonable. Note that the functions asked for may sometimes already be called and the information from the function that you need is already in the prompt, so read carefully. Note that you DO NOT have access to run any code, you can only read, think, and write about the existing skills and knowledge.\\n        \\n        You will be given this information:\\n        Task or question: ...\\n        Skills & knowledge: You only have these skills and pieces of knowledge in the format of (function name which represents a concept / ability, a description of that concept and ability that you can invoke) to help you write the steps to achieve this task or answer this question. You can call a function (sometimes with or without arguments) to just get more information too.\\n        Files: ... \\n        Current state steps: ...\\n        Current state output after executing steps: ...\\n        Execution errors: ...\\n        Critique: ...\\n        \\n        Please output your list of steps that can be followed and answer the question and address any critiques.\"}, {'role': 'user', 'content': 'Task or question: What is the distribution of the sale prices in the dataset?\\n        Skills & knowledge: [\"(\\'read_file\\', \\'Get the text from the file\\')\\\\n\", \"(\\'write_file\\', \\'Write text to a file\\')\\\\n\", \\'(\\\\\\'web_search\\\\\\', \"Given a prompt, I\\\\\\'ll return back my web search information about it\")\\\\n\\', \\'(\\\\\\'think\\\\\\', \"Given a prompt, I\\\\\\'ll return back my thoughts on it.\")\\\\n\\', \"(\\'num_children\\', \\'This paper talks about how many girls and boys are in this family\\')\\\\n\", \"(\\'columns_and_descriptions\\', \\'The question was what are the columns and their descriptions in the training set and the test set. The columns and their descriptions in the training set and the test set are as follows:\\\\\\\\n\\\\\\\\nTraining Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nTest Set:\\\\\\\\n1. MSSubClass: Identifies the type of dwelling involved in the sale.\\\\\\\\n2. MSZoning: Identifies the general zoning classification of the sale.\\\\\\\\n3. LotFrontage: Linear feet of street connected to property.\\\\\\\\n4. LotArea: Lot size in square feet.\\\\\\\\n5. Street: Type of road access to property.\\\\\\\\n6. Alley: Type of alley access to property.\\\\\\\\n7. LotShape: General shape of property.\\\\\\\\n8. LandContour: Flatness of the property.\\\\\\\\n9. Utilities: Type of utilities available.\\\\\\\\n10. LotConfig: Lot configuration.\\\\\\\\n11. LandSlope: Slope of property.\\\\\\\\n12. Neighborhood: Physical locations within Ames city limits.\\\\\\\\n\\\\\\\\nPlease note that these are just a few examples of the columns and their descriptions. There may be more columns in the actual datasets.\\')\\\\n\"]\\n        Files: [\\'train.csv - the training set\\', \\'test.csv - the test set\\', \\'data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\\', \\'sample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\\', \"data_fields.txt - a brief version of what you\\'ll find in the data description file.\"]\\n        Current state solution: None\\n        Current state output after executing steps: None\\n        Execution errors: None\\n        Critique: None'}]\n",
    "\n",
    "# create the chat completion\n",
    "print(\"Prompt messages: \", messages)\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    functions=skill_manager.functions,\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "print(\"Completion info: \", completion)\n",
    "response_message = completion[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill_manager.available_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
